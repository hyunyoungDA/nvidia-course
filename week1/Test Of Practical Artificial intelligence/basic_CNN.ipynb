{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2a066c6",
   "metadata": {},
   "source": [
    "### 데이터 불러오기 및 탐색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "639d83ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.datasets import fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0743d549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "# fashion_mnist.load_data() 함수는 기본적으로 데이터를 네 가지 형태로 묶어서 반환하도록 설계되어 있음. \n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db033a35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (10000, 28, 28))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (size, height, width)\n",
    "train_images.shape, test_images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1e3ec6",
   "metadata": {},
   "source": [
    "### 데이터 전처리 (20점)\n",
    "\n",
    "- LeNet-5의 입력 크기에 맞게 32 * 32 픽셀 크기로 변환하시오"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baba6345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불러온 데이터의 형태는 (60000, 28, 28)인데 CNN에서는 채널이라는 차원을 추가로 기대함.\n",
    "# 따라서 reshape으로 채널 차원을 추가해줘야됨 \n",
    "train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "test_images = test_images.reshape((10000, 28, 28, 1))\n",
    "\n",
    "# 이미지 크기를 LeNet 모델의 입력에 맞게 32*32로 변경 \n",
    "train_images = tf.image.resize(train_images, (32,32))\n",
    "test_images = tf.image.resize(test_images, (32,32))\n",
    "\n",
    "# 검증 데이터 분할 \n",
    "val_size = 10000\n",
    "val_images = train_images[:val_size]\n",
    "val_labels = train_labels[:val_size]\n",
    "train_images = train_images[val_size:]\n",
    "train_labels = train_labels[val_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c541173",
   "metadata": {},
   "source": [
    "### LeNet -5 모델 구현 (40점)\n",
    "\n",
    "<img src=\"https://camo.githubusercontent.com/bc995d7c5c1736a7722268f667ac6dc3b45abe00e6f1eed3cd0137bae1655608/687474703a2f2f75706c6f61642d696d616765732e6a69616e7368752e696f2f75706c6f61645f696d616765732f333632333732302d386262323833643032323835656438612e706e673f696d6167654d6f6772322f6175746f2d6f7269656e742f7374726970253743696d61676556696577322f322f772f31323430\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99a3f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential(name = \"LeNet-5\")\n",
    "\n",
    "# input_shape: Conv2D 레이어에 들어오는 데이터의 형태를 넣어줌 \n",
    "model.add(Conv2D(6, kernel_size = (5,5), activation = 'relu', input_shape = (32,32,1)))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "model.add(Conv2D(16, kernel_size = (5,5), activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(120, activation = \"relu\"))\n",
    "model.add(Dense(84, activation = 'relu'))\n",
    "model.add(Dense(10, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eba9440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sparse_categorical_crossentropy는 숫자 인코딩이 되어있을 때 사용 \n",
    "model.compile(optimizer = \"adam\", loss = \"sparse_categorical_crossentropy\", metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8569a119",
   "metadata": {},
   "source": [
    "### 모델 학습 (20점)\n",
    "\n",
    "- epochs는 10으로 설정합니다.\n",
    "- batch_size는 32로 설정합니다.\n",
    "- 학습 데이터로 `train_images`와 `train_labels`를 사용합니다.\n",
    "- 검증 데이터로 `val_images`와 `val_labels` 를 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94b46e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit(\n",
    "  train_images, train_labels, epochs = 10, batch_size = 32, validation_data = (val_images, val_labels)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba2ca3d",
   "metadata": {},
   "source": [
    "### 모델 평가 (20점)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf940a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images, test_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kerasenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
