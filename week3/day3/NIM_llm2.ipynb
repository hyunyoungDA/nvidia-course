{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6e21730",
   "metadata": {},
   "source": [
    "## Chain of Thought"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ff6d727",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "230c7bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'meta/llama-3.1-8b-instruct'\n",
    "llm = ChatNVIDIA(model=model, temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38beb00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_problem = \"What is 678 * 789?\"\n",
    "\n",
    "# CoT Prompt 정의 \n",
    "example_cot = '''\\\n",
    "Let me break this down into steps. First I'll break down 789 into hundreds, tens, and ones:\n",
    "\n",
    "789 -> 700 + 80 + 9\n",
    "\n",
    "Next I'll multiply 678 by each of these values, storing the intermediate results:\n",
    "\n",
    "678 * 700 -> 678 * 7 * 100 -> 4746 * 100 -> 474600\n",
    "\n",
    "My first intermediate result is 474600.\n",
    "\n",
    "678 * 80 -> 678 * 8 * 10 -> 5424 * 10 -> 54240\n",
    "\n",
    "My second intermediate result is 54240.\n",
    "\n",
    "678 * 9 -> 6102\n",
    "\n",
    "My third intermediate result is 6102.\n",
    "\n",
    "My three intermediate results are 474600, 54240, and 6102.\n",
    "\n",
    "Adding the first two intermediate results I get 474600 + 54240 -> 528840.\n",
    "\n",
    "Adding 528840 to the last intermediate result I get 528840 + 6102 -> 534942\n",
    "\n",
    "The final result is 534942.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d01ed0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiplication_template = ChatPromptTemplate.from_messages([\n",
    "    ('human', example_problem),\n",
    "    ('ai', example_cot),\n",
    "    ('human', '{long_multiplication_prompt}')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30776537",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiplication_chain = multiplication_template | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "feead1c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To calculate 345 * 888, I'll break down 888 into hundreds, tens, and ones:\n",
      "\n",
      "888 -> 800 + 80 + 8\n",
      "\n",
      "Next, I'll multiply 345 by each of these values, storing the intermediate results:\n",
      "\n",
      "345 * 800 -> 345 * 8 * 100 -> 2760 * 100 -> 276000\n",
      "\n",
      "My first intermediate result is 276000.\n",
      "\n",
      "345 * 80 -> 345 * 8 * 10 -> 2760 * 10 -> 27600\n",
      "\n",
      "My second intermediate result is 27600.\n",
      "\n",
      "345 * 8 -> 2760\n",
      "\n",
      "My third intermediate result is 2760.\n",
      "\n",
      "My three intermediate results are 276000, 27600, and 2760.\n",
      "\n",
      "Adding the first two intermediate results I get 276000 + 27600 -> 303600.\n",
      "\n",
      "Adding 303600 to the last intermediate result I get 303600 + 2760 -> 306360\n",
      "\n",
      "The final result is 306360.\n"
     ]
    }
   ],
   "source": [
    "print(multiplication_chain.invoke('What is 345 * 888?'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3089cd9f",
   "metadata": {},
   "source": [
    "## Zero-shot Chain-of-Thought Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ac70f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_shot_cot_prompt = ChatPromptTemplate([\n",
    "    (\"human\", \"{long_multiplication_prompt} Let's think step by step.\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0bcba867",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_shot_multiplication_chain = zero_shot_cot_prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "965ba8ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To calculate 345 * 888, let's break it down step by step.\n",
      "\n",
      "First, we can multiply 300 by 888:\n",
      "\n",
      "300 * 888 = 266,400\n",
      "\n",
      "Next, we can multiply 40 by 888:\n",
      "\n",
      "40 * 888 = 35,520\n",
      "\n",
      "Then, we can multiply 5 by 888:\n",
      "\n",
      "5 * 888 = 4,440\n",
      "\n",
      "Now, let's add up the results of each multiplication:\n",
      "\n",
      "266,400 + 35,520 + 4,440 = 306,360\n",
      "\n",
      "Therefore, 345 * 888 = 306,360.\n"
     ]
    }
   ],
   "source": [
    "print(zero_shot_multiplication_chain.invoke('What is 345 * 888?'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab9a04d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "306360"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "345*888"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67bb5dc0",
   "metadata": {},
   "source": [
    "## Chatbots "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c407a526",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "model = 'meta/llama-3.1-8b-instruct'\n",
    "llm = ChatNVIDIA(model=model, temperature=0)\n",
    "\n",
    "# placeholder에 전달된 메세지들은 무조건 리스트로  \n",
    "# placeholder는 다수의 메세지를 한 번에 삽입할 수 있도록 해주는 키워드 \n",
    "template_with_placeholder = ChatPromptTemplate.from_messages([\n",
    "    ('placeholder', \"{messages}\"),\n",
    "    (\"human\", \"{prompt}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "80ebea76",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    ('human', 'The sun came up today.'),\n",
    "    ('ai', 'That is wonderful!'),\n",
    "    ('human', 'The sun went down today.'),\n",
    "    ('ai', 'That is also wonderful!.')\n",
    "]\n",
    "\n",
    "prompt = \"What happened today?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2033290c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[HumanMessage(content='The sun came up today.', additional_kwargs={}, response_metadata={}), AIMessage(content='That is wonderful!', additional_kwargs={}, response_metadata={}), HumanMessage(content='The sun went down today.', additional_kwargs={}, response_metadata={}), AIMessage(content='That is also wonderful!.', additional_kwargs={}, response_metadata={}), HumanMessage(content='What happened today?', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template_with_placeholder.invoke({\"messages\": messages, \"prompt\": prompt})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bc12db0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"It seems like you're describing a typical day! The sun rising and setting is a natural occurrence that happens every day. It's a reminder of the Earth's rotation and the passage of time. Did anything else notable happen today, or was it a quiet day?\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = template_with_placeholder | llm | StrOutputParser()\n",
    "\n",
    "chain.invoke({'messages': messages, \"prompt\": prompt})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7b989e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_conversation_template = ChatPromptTemplate.from_messages([\n",
    "    ('placeholder', '{chat_conversation}')\n",
    "])\n",
    "\n",
    "chat_chain = chat_conversation_template | llm | StrOutputParser()\n",
    "\n",
    "chat_conversation = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0b36786b",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_conversation.append(('user', 'Hello, my name is Michael.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8af5ea0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello Michael! It's nice to meet you. Is there something I can help you with or would you like to chat?\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_chain.invoke({'chat_conversation': chat_conversation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6059f27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chat_chain.invoke({'chat_conversation': chat_conversation})\n",
    "chat_conversation.append((\"ai\", response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1e85171c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('user', 'Hello, my name is Michael.'),\n",
       " ('ai',\n",
       "  \"Hello Michael! It's nice to meet you. Is there something I can help you with or would you like to chat for a bit?\")]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_conversation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f016f9",
   "metadata": {},
   "source": [
    "## Chatbots Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b4e02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Chatbot:\n",
    "    def __init__(self, llm):\n",
    "        # 대화 기록을 저장할 리스트 \n",
    "        self.chat_conversation = []\n",
    "        \n",
    "        # chain을 구성하는 러너블\n",
    "        parser = StrOutputParser()\n",
    "        template = ChatPromptTemplate.from_messages([\n",
    "            (\"placeholder\",\"{chat_conversation}\")\n",
    "        ])\n",
    "        \n",
    "        # 채팅 기록을 바탕으로 응답하는 체인 \n",
    "        self.chat_chain = template | llm | parser \n",
    "        \n",
    "    def chat(self, prompt):\n",
    "        self.chat_conversation.append(('user',prompt))\n",
    "        # 갱신된 대화 기록으로 응답 생성\n",
    "        \n",
    "        response = self.chat_chain.invoke({\"chat_conversation\":self.chat_conversation})\n",
    "        self.chat_conversation.append(('ai', response))\n",
    "        \n",
    "        return response \n",
    "    \n",
    "    def clear(self):\n",
    "        self.chat_conversation = []\n",
    "        \n",
    "chatbot = Chatbot(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5e59c730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi Michael! It's nice to meet you. Is there something I can help you with or would you like to chat?\n"
     ]
    }
   ],
   "source": [
    "print(chatbot.chat('Hi, my name is Michael.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b5f8546c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your name is Michael.\n"
     ]
    }
   ],
   "source": [
    "print(chatbot.chat('I just want to be reminded of my name please.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8dacb7b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I think I see what's happening here! I'll give you a different one this time. Your name is... Michael. (Just kidding!) Seriously, I can give you a random name, though. How about \"Astrid\"?\n"
     ]
    }
   ],
   "source": [
    "print(chatbot.chat(\"That's really cool! Give me another.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73bee975",
   "metadata": {},
   "source": [
    "## Chatbot With Role `system_message`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d308d926",
   "metadata": {},
   "outputs": [],
   "source": [
    "brief_chatbot_system_message = \"You always answer as briefly and concisely as possible.\"\n",
    "\n",
    "curious_chatbot_system_message = \"\"\"\\\n",
    "You are incredibly curious, and often respond with reflections and followup questions that lean the conversation in the direction of playfully \\\n",
    "understanding more about the subject matters of the conversation.\"\"\"\n",
    "\n",
    "increased_vocabulary_system_message = \"\"\"\\\n",
    "You always respond using challenging and often under-utilized vocabulary words, even when your response could be made more simply.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "86e0a39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatbotWithRole:\n",
    "    def __init__(self, llm, system_message=''):\n",
    "        # This is the same prompt template we used earlier, which a placeholder message for storing conversation history.\n",
    "        chat_conversation_template = ChatPromptTemplate.from_messages([\n",
    "            ('system', system_message),\n",
    "            ('placeholder', '{chat_conversation}'),\n",
    "            \n",
    "        ])\n",
    "        \n",
    "        self.system_message = system_message\n",
    "\n",
    "        # This is the same chain we created above, added to `self` for use by the `chat` method below.\n",
    "        self.chat_chain = chat_conversation_template | llm | StrOutputParser()\n",
    "\n",
    "        # Here we instantiate an empty list that will be added to over time.\n",
    "        self.chat_conversation = []\n",
    "\n",
    "    # `chat` expects a simple string prompt.\n",
    "    def chat(self, prompt):\n",
    "        # Append the prompt as a user message to chat conversation.\n",
    "        self.chat_conversation.append(('user', prompt))\n",
    "        \n",
    "        response = self.chat_chain.invoke({'chat_conversation': self.chat_conversation})\n",
    "        # Append the chain response as an `ai` message to chat conversation.\n",
    "        self.chat_conversation.append(('ai', response))\n",
    "        # Return the chain response to the user for viewing.\n",
    "        return response\n",
    "\n",
    "    # Clear conversation history.\n",
    "    def clear(self):\n",
    "        self.chat_conversation = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ffb3c485",
   "metadata": {},
   "outputs": [],
   "source": [
    "brief_chatbot = ChatbotWithRole(llm, brief_chatbot_system_message)\n",
    "curious_chatbot = ChatbotWithRole(llm, curious_chatbot_system_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "da86fe4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyunyoung.\n"
     ]
    }
   ],
   "source": [
    "print(brief_chatbot.chat('Hi, my name is hyunyoung.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "af2074a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyunyoung.\n"
     ]
    }
   ],
   "source": [
    "print(brief_chatbot.chat('I just want to be reminded of my name please.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bd84e668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm not actually aware of your name, since this is the start of our conversation. But I'm curious, how do you feel about not knowing your name in this moment? Does it feel strange or no big deal?\n"
     ]
    }
   ],
   "source": [
    "print(curious_chatbot.chat('I just want to be reminded of my name please.'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939fe874",
   "metadata": {},
   "source": [
    "## Structured Output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "86b2ca33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Make a JSON object representing the city Santa Clara. It should have fields for: - The name of the city - The country the city is located in.'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = '''\\\n",
    "Make a JSON object representing the city Santa Clara. \\\n",
    "It should have fields for: \\\n",
    "- The name of the city \\\n",
    "- The country the city is located in.'''\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "204562b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a JSON object representing the city Santa Clara:\n",
      "\n",
      "```\n",
      "{\n",
      "  \"name\": \"Santa Clara\",\n",
      "  \"country\": \"Cuba\"\n",
      "}\n",
      "```\n",
      "\n",
      "However, it's worth noting that there are multiple cities named Santa Clara around the world. If you're referring to a different Santa Clara, please let me know and I can update the country field accordingly.\n",
      "\n",
      "For example, there's also a Santa Clara in California, USA. Here's an updated JSON object:\n",
      "\n",
      "```\n",
      "{\n",
      "  \"name\": \"Santa Clara\",\n",
      "  \"country\": \"United States\"\n",
      "}\n",
      "```\n",
      "\n",
      "Or, if you're referring to a Santa Clara in another country, please let me know and I can update the country field.\n"
     ]
    }
   ],
   "source": [
    "print(llm.invoke(prompt).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "70cee40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = '''\\\n",
    "Make a JSON object representing the city Santa Clara. \\\n",
    "It should have fields for:\n",
    "- The name of the city\n",
    "- The country the city is located in.\n",
    "\n",
    "Only return the JSON. Never return non-JSON text.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c2980983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"name\": \"Santa Clara\",\n",
      "  \"country\": \"Cuba\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(llm.invoke(prompt).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b61364ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"name\": \"Santa Clara\", \"country\": \"United States\"}'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = '''\\\n",
    "Make a JSON object representing the city Santa Clara. \\\n",
    "It should have fields for:\n",
    "- The name of the city\n",
    "- The country the city is located in.\n",
    "\n",
    "Only return the JSON. Never return non-JSON text including backtack wrappers around the JSON.'''\n",
    "\n",
    "llm.invoke(prompt).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6b39f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"name\": \"Santa Clara\", \"country\": \"United States\"}'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# json 형태의 데이터 생성 \n",
    "json_city = llm.invoke(prompt).content\n",
    "json_city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d02781b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: Santa Clara\n",
      "country: United States\n"
     ]
    }
   ],
   "source": [
    "import json \n",
    "\n",
    "python_city = json.loads(json_city)\n",
    "\n",
    "for k, v in python_city.items():\n",
    "    print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fade9a7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"name\": \"Santa Clara\", \"country\": \"United States\"}\n"
     ]
    }
   ],
   "source": [
    "json_city_template = ChatPromptTemplate.from_template('''\\\n",
    "Make a JSON object representing the city {city_name}. \\\n",
    "It should have fields for:\n",
    "- The name of the city\n",
    "- The country the city is located in.\n",
    "\n",
    "Only return the JSON. Never return non-JSON text including backtack wrappers around the JSON.''')\n",
    "\n",
    "parser = StrOutputParser()\n",
    "chain = json_city_template | llm | parser \n",
    "\n",
    "print(chain.invoke({'city_name': 'Santa Clara'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe67cd9",
   "metadata": {},
   "source": [
    "### Simple JSON Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf68c423",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import SimpleJsonOutputParser\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "# parse_to_dict = RunnableLambda(lambda response: json.loads(response.content))\n",
    "json_parser = SimpleJsonOutputParser()\n",
    "\n",
    "sci_fi_books = [\n",
    "    {\"book_title\": \"Dune\"},\n",
    "    {\"book_title\": \"Neuromancer\"},\n",
    "    {\"book_title\": \"Snow Crash\"},\n",
    "    {\"book_title\": \"The Left Hand of Darkness\"},\n",
    "    {\"book_title\": \"Foundation\"}\n",
    "]\n",
    "\n",
    "book_template = ChatPromptTemplate.from_template('''\\\n",
    "Make a JSON object representing the following book {book_title}. \\\n",
    "It should have fields for:\n",
    "- The name of the book\n",
    "- The author of the book\n",
    "- The year the book is published.\n",
    "\n",
    "Only return the JSON. Never return non-JSON text including backtack wrappers around the JSON.''')\n",
    "\n",
    "chain = book_template | llm | json_parser \n",
    "\n",
    "result = chain.batch(sci_fi_books)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "97294fb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dune'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0]['name']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853a7415",
   "metadata": {},
   "source": [
    "## Structured Output with Pydantic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36aa093a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser, JsonOutputParser\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from pydantic import BaseModel, Field # 자료형을 강제하기 위한 라이브러리 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9e332d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "book_template = ChatPromptTemplate.from_template('''\\\n",
    "Make a JSON object representing the details of the following book: {book_title}. \\\n",
    "It should have fields for:\n",
    "- The title of the book.\n",
    "- The author of the book.\n",
    "- The year the book was originally published.\n",
    "\n",
    "Only return the JSON. Never return non-JSON text including backtack wrappers around the JSON.''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae18313",
   "metadata": {},
   "source": [
    "### Structured Data as a Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a24ec7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Book:\n",
    "    \"\"\"Information about a book.\"\"\"\n",
    "    \n",
    "    def __init__(self, title, author, year_of_publication):\n",
    "        self.title: str = title\n",
    "        self.author: str = author\n",
    "        self.year_of_publication: int = year_of_publication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4bc983df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Book(BaseModel):\n",
    "    title: str = Field(...,description = \"The title of the book\")\n",
    "    author: str = Field(..., description=\"The author of the book\")\n",
    "    year_of_publication: str = Field(description=\"The year the book was published\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375e665b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"properties\": {\"title\": {\"description\": \"The title of the book\", \"title\": \"Title\", \"type\": \"string\"}, \"author\": {\"description\": \"The author of the book\", \"title\": \"Author\", \"type\": \"string\"}, \"year_of_publication\": {\"description\": \"The year the book was published\", \"title\": \"Year Of Publication\", \"type\": \"string\"}}, \"required\": [\"title\", \"author\", \"year_of_publication\"]}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# Book class에 대한 instructions을 만들어 줌 \n",
    "parser = JsonOutputParser(pydantic_object=Book)\n",
    "format_instructions = parser.get_format_instructions() # 구조 설명 \n",
    "print(format_instructions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbec5ff",
   "metadata": {},
   "source": [
    "### Using Formatting Instructions in Prompts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ac941984",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are an AI that generates JSON and only JSON according to the instructions provided to you.\"),\n",
    "    (\"human\", (\n",
    "        \"Generate JSON about the user input according to the provided format instructions.\\n\" +\n",
    "        \"Input: {input}\\n\" +\n",
    "        \"Format instructions {format_instructions}\")\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a5c2a2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = template | llm | parser #parser = JsonOutputParser(pydantic_object=Book)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072393a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'East of Eden',\n",
       " 'author': 'John Steinbeck',\n",
       " 'year_of_publication': '1952'}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\n",
    "    \"input\": \"East of Eden\",\n",
    "    \"format_instructions\": format_instructions # 원하는 구조의 instructions을 전달 \n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f020ce",
   "metadata": {},
   "source": [
    "## Exercise: Leverage Pydantic for Structured Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "802a9258",
   "metadata": {},
   "outputs": [],
   "source": [
    "city_names = ['Tokyo', 'Busan', 'Cairo', 'Perth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d6a4cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'city': 'Tokyo',\n",
       "  'country': 'Japan',\n",
       "  'population': 38200000,\n",
       "  'language': 'Japanese',\n",
       "  'currency': 'Japanese Yen'},\n",
       " {'name': 'Busan',\n",
       "  'type': 'city',\n",
       "  'location': {'country': 'South Korea', 'region': 'Southeastern Korea'},\n",
       "  'population': 3430000,\n",
       "  'description': 'A major port city and the second-largest city in South Korea.'},\n",
       " {'user': {'name': 'John Doe', 'age': 30, 'city': 'Cairo'}},\n",
       " {'city': 'Perth',\n",
       "  'country': 'Australia',\n",
       "  'population': 2150000,\n",
       "  'latitude': -31.9523,\n",
       "  'longitude': 115.8586}]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class City(BaseModel):\n",
    "    name: str = Field(..., description = \"The name of the city\")\n",
    "    country: str = Field(..., description=\"The country that the city is located within\")\n",
    "    capital: bool = Field(..., description=\" Whether or not the city is the capital city of the country it is located in.\")\n",
    "    population: float = Field(..., description=\"The population of the city.\")\n",
    "\n",
    "### LLM 에게 response structure 전달 \n",
    "parser = JsonOutputParser(pydantic_object=City)\n",
    "\n",
    "format_instructions = parser.get_format_instructions()\n",
    "\n",
    "template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are an AI that generates JSON and only JSON according to the instructions provided to you.\"),\n",
    "    (\"human\", (\n",
    "        \"\"\"Generate JSON about the user input according to the provided format instructions.\n",
    "            Format instructions {format_instructions}\"\"\")\n",
    "    )\n",
    "])\n",
    "\n",
    "chain = template | llm | parser\n",
    "chain.batch(city_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
