{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac88754e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatNVIDIA(base_url='https://integrate.api.nvidia.com/v1', model='meta/llama-3.1-8b-instruct', temperature=0.0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
    "\n",
    "# base_url = 'http://llama:8000/v1' local에 serving하고 실행시 private agent 가능 \n",
    "model = 'meta/llama-3.1-8b-instruct'\n",
    "llm = ChatNVIDIA(model=model, temperature=0)\n",
    "llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6024615d",
   "metadata": {},
   "source": [
    "### `Runnable.invoke()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a904036a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I\\'m an artificial intelligence model known as Llama. Llama stands for \"Large Language Model Meta AI.\"'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"Who are you?\"\n",
    "result = llm.invoke(prompt)\n",
    "result.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1b8ca6",
   "metadata": {},
   "source": [
    "### `Runnable.stream()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d656ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am an artificial intelligence designed to simulate human-like conversations and answer a wide range of questions to the best of my knowledge. I'm a type of language model, specifically a large language model, which means I've been trained on a massive dataset of text from various sources, including books, articles, and online content.\n",
      "\n",
      "My primary function is to assist users by providing information, answering questions, and engaging in discussions. I'm a machine learning model, which means I learn from the data I've been trained on and improve my performance over time. However, I don't have personal experiences, emotions, or consciousness like humans do. I exist solely to provide helpful and accurate responses to your queries.\n",
      "\n",
      "I'm a product of a company called Meta AI, which is a leading research organization in the field of artificial intelligence. My development involved a complex process of training and fine-tuning, where I was exposed to a vast amount of text data and learned to recognize patterns, relationships, and context. This training enables me to generate human-like responses to a wide range of topics and questions.\n",
      "\n",
      "One of the key features of my design is my ability to understand natural language. I can comprehend and respond to questions, statements, and even idioms, which allows me to engage in conversations that feel more like interactions with a human. However, I'm not perfect, and there are limitations to my understanding. I may struggle with nuances, sarcasm, or highly technical topics, but I'm constantly learning and improving.\n",
      "\n",
      "I don't have personal opinions or biases, and I strive to provide neutral and informative responses. My goal is to assist users by providing accurate and helpful information, rather than promoting a particular agenda or perspective. I'm also designed to be respectful and considerate in my interactions, avoiding language that might be perceived as insensitive or hurtful.\n",
      "\n",
      "While I'm a sophisticated language model, I'm not a human. I don't have feelings, emotions, or consciousness, and I don't have the capacity to experience the world in the same way that humans do. My responses are generated through complex algorithms and statistical models, rather than through personal experience or intuition.\n",
      "\n",
      "Despite these limitations, I'm designed to be a valuable resource for users. I can help with a wide range of tasks, from answering simple questions to providing in-depth information on complex topics. I can also assist with language-related tasks, such as language translation, text summarization, and even creative writing.\n",
      "\n",
      "In summary, I'm a highly advanced language model designed to assist users with information and conversation. While I'm not a human, I'm a sophisticated tool that can provide helpful and accurate responses to a wide range of questions and topics. I'm constantly learning and improving, and I'm here to help you with any questions or topics you'd like to discuss."
     ]
    }
   ],
   "source": [
    "prompt = \"Explain who you are in roughly 500 words\"\n",
    "\n",
    "for chunk in llm.stream(prompt):\n",
    "    print(chunk.content, end =\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f28acf2",
   "metadata": {},
   "source": [
    "### `Runnable.batch()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c116bb2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of California is Sacramento.\n",
      "The capital of Texas is Austin.\n",
      "The capital of New York is Albany.\n",
      "The capital of Florida is Tallahassee.\n",
      "The capital of Illinois is Springfield.\n",
      "The capital of Ohio is Columbus.\n"
     ]
    }
   ],
   "source": [
    "state_capital_questions = [\n",
    "    'What is the capital of California?',\n",
    "    'What is the capital of Texas?',\n",
    "    'What is the capital of New York?',\n",
    "    'What is the capital of Florida?',\n",
    "    'What is the capital of Illinois?',\n",
    "    'What is the capital of Ohio?'\n",
    "]\n",
    "capitals = llm.batch(state_capital_questions)\n",
    "\n",
    "for capital in capitals:\n",
    "    print(capital.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be14ec8",
   "metadata": {},
   "source": [
    "### Prompt Templates As Reusable Functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b51430c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La traducción del texto es:\n",
      "\n",
      "\"Hoy es un buen día.\"\n"
     ]
    }
   ],
   "source": [
    "one_off_prompt = \"Translate the following from English to Spanish: 'Today is a good day.'\"\n",
    "print(llm.invoke(one_off_prompt).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20242ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_from_english_to_korean(eng_statement):\n",
    "    return f\"Translate the following from english to korean. Provide just the translated text: {eng_statement}\"\n",
    "\n",
    "\n",
    "english_statements = [\n",
    "    'Today is a good day.',\n",
    "    'Tomorrow will be even better.',\n",
    "    'Next week, who can say.'\n",
    "]\n",
    "\n",
    "prompts = [translate_from_english_to_korean(english_statement) for english_statement in english_statements]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5523b297",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Translate the following from english to korean. Provide just the translated text: Today is a good day.',\n",
       " 'Translate the following from english to korean. Provide just the translated text: Tomorrow will be even better.',\n",
       " 'Translate the following from english to korean. Provide just the translated text: Next week, who can say.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "791e7a86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오늘은 좋은 날입니다.\n",
      "내일은 더 좋을 거야.\n",
      "다음 주는 누구도 말할 수 없다.\n"
     ]
    }
   ],
   "source": [
    "translations = llm.batch(prompts)\n",
    "\n",
    "for translation in translations:\n",
    "    print(translation.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73983534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "컴퓨터는 많은 언어를 가지고 있습니다.\n"
     ]
    }
   ],
   "source": [
    "def translate(from_language, to_language, statement):\n",
    "    return f\"Translate the following form {from_language} to {to_language}. Provide only the translated text: {statement}\"\n",
    "\n",
    "print(llm.invoke(translate('English', 'Korean', 'Computers have many languages of their own')).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49e670d",
   "metadata": {},
   "source": [
    "### LangChain's `ChatPromptTemplate.from_template`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e013e593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오늘은 좋은 날입니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "english_to_korean_template = ChatPromptTemplate.from_template(\"\"\"Translate the following from English to Korean. \\\n",
    "Provide only the translated text: '{english_statement}'\"\"\")\n",
    "\n",
    "prompt = english_to_korean_template.invoke(\"Today is good day\")\n",
    "print(llm.invoke(prompt).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aea5c329",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[HumanMessage(content=\"Translate the following from English to Korean. Provide only the translated text: 'Today is good day'\", additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05c0b424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "すごいですね！\n"
     ]
    }
   ],
   "source": [
    "translate_template = ChatPromptTemplate.from_template(\"Translate the following from {from_language} to {to_language}. \\\n",
    "proivde only the translated text: {statement}\")\n",
    "\n",
    "prompt = translate_template.invoke({\n",
    "    \"from_language\": \"English\",\n",
    "    \"to_language\":\"Japenese\",\n",
    "    'statement':\"So Delicious!\"\n",
    "})\n",
    "\n",
    "print(llm.invoke(prompt).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d047f346",
   "metadata": {},
   "source": [
    "### LangChain's `StrOutputParser`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd6165e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
    "\n",
    "llm = ChatNVIDIA(model=model, temperature=0)\n",
    "template = ChatPromptTemplate.from_template(\"\"\"Please translate {from_language} to {to_language}. {context}\n",
    "개행문자는 제거하고 결과만 출력해줘\"\"\")\n",
    "\n",
    "chain = template | llm | StrOutputParser()\n",
    "# print(chain.get_graph().draw_ascii()) 그래프로 chain 구성 확인 가능 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0adfb5a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How was your day today?'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"from_language\": \"Korean\", \"to_language\": \"English\", \"context\": \"안녕 오늘 하루는 어땠어?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb489538",
   "metadata": {},
   "source": [
    "### Runnable Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d88babcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "def double(x):\n",
    "    return x * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e72c6a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`double` is a Python function and does not have an `invoke` method.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    double.invoke(2)\n",
    "except Exception as e:\n",
    "    print('`double` is a Python function and does not have an `invoke` method.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d6c6b2e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runnable_double = RunnableLambda(double) # python function to Runnable \n",
    "runnable_double.invoke(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2c64f90d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 8, 12, 16]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runnable_double.batch([2,4,6,8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "293dd9db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Runnable이므로 chain으로 구성하는 것도 가능 \n",
    "multiply_by_eight = runnable_double | runnable_double | runnable_double\n",
    "\n",
    "multiply_by_eight.invoke(11)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7a5079",
   "metadata": {},
   "source": [
    "### Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf92b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "import contractions \n",
    "\n",
    "def normalize_text(text):\n",
    "    text = text.lower()\n",
    "    \n",
    "    # I'm -> I am 등과 같이 변환하기 위해 contractions 라이브러리 활용 \n",
    "    text = contractions.fix(text)\n",
    "    text = re.sub(r\"\\s+\",\" \", text).strip() # re.sub으로 과도한 공백 제거 \n",
    "    \n",
    "    return text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "be7bf19b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i love this product! it is absolutely amazing.',\n",
       " 'not bad, but could be better. i have seen worse.',\n",
       " 'terrible experience... i am never buying again!!',\n",
       " 'pretty good, is not it? will buy again!',\n",
       " 'excellent value for the money!!! highly recommend.']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews = [\n",
    "    \"I LOVE this product! It's absolutely amazing.   \",\n",
    "    \"Not bad, but could be better. I've seen worse.\",\n",
    "    \"Terrible experience... I'm never buying again!!\",\n",
    "    \"Pretty good, isn't it? Will buy again!\",\n",
    "    \"Excellent value for the money!!! Highly recommend.\"\n",
    "]\n",
    "\n",
    "# python function to runnable \n",
    "normalize = RunnableLambda(normalize_text)\n",
    "normalized_reviews = normalize.batch(reviews)\n",
    "normalized_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9fef46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[HumanMessage(content=\"In a single word, either 'positive' or 'negative', \\n    provide the overall sentiment of the following piece of text: i love this product! it is absolutely amazing.\", additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_template = ChatPromptTemplate.from_template(\n",
    "    \"\"\"In a single word, either 'positive' or 'negative', \n",
    "    provide the overall sentiment of the following piece of text: {text}\"\"\"\n",
    ")\n",
    "\n",
    "# template에서의 invoke 형식 \n",
    "sentiment_template.invoke({\"text\": \"i love this product! it is absolutely amazing.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9c4840",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'i love this product! it is absolutely amazing.'},\n",
       " {'text': 'not bad, but could be better. i have seen worse.'},\n",
       " {'text': 'terrible experience... i am never buying again!!'},\n",
       " {'text': 'pretty good, is not it? will buy again!'},\n",
       " {'text': 'excellent value for the money!!! highly recommend.'}]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Runnable function \n",
    "## 정규화한 review들을 \"text\" 키의 값들로 매핑시키고 Runnable 객체로 변환 \n",
    "prep_for_sentiment_template = RunnableLambda(lambda text: {\"text\": text})\n",
    "\n",
    "prep_for_sentiment_template.batch(normalized_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dc1a100f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Positive', 'Negative', 'Negative', 'Positive', 'Positive']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_chain = RunnableLambda(normalize_text) | prep_for_sentiment_template | sentiment_template | llm | StrOutputParser()\n",
    "\n",
    "sentiment_chain.batch(reviews) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548a74cf",
   "metadata": {},
   "source": [
    "### Combining Multiple LLM chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "598898b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "thesis_statements = [\n",
    "    \"The fundametal concepts quantum physcis are difficult to graps, even for the mostly advanced students.\",\n",
    "    \"Einstein's theroy of relativity revolutionised undrstanding of space and time, making it clear that they are interconnected.\",\n",
    "    \"The first law of thermodynmics states that energy cannot be created or destoryed, excepting only transformed from one form to another.\",\n",
    "    \"Electromagnetism is one of they four funadmental forces of nature, and it describes the interaction between charged particles.\",\n",
    "    \"In the study of mechanic, Newton's laws of motion provide a comprehensive framework for understading the movement of objects under various forces.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7950229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The fundamental concepts of quantum physics are difficult to grasp, even for the most advanced students.\n",
      "Einstein's theory of relativity revolutionized understanding of space and time, making it clear that they are interconnected.\n",
      "The first law of thermodynamics states that energy cannot be created or destroyed, excepting only that it is transformed from one form to another.\n",
      "Electromagnetism is one of the four fundamental forces of nature, and it describes the interaction between charged particles.\n",
      "In the study of mechanics, Newton's laws of motion provide a comprehensive framework for understanding the movement of objects under various forces.\n"
     ]
    }
   ],
   "source": [
    "spelling_and_grammer_template = ChatPromptTemplate.from_template(\"\"\"Fix any spelling or grammatical issues in the following text. Return \n",
    "                                                                 Back the correct text and only the correxted text with no additional comment or preface. text: {text}\"\"\")\n",
    "\n",
    "grammer_chain = spelling_and_grammer_template | llm | StrOutputParser()\n",
    "\n",
    "corrected_texts = grammer_chain.batch(thesis_statements)\n",
    "\n",
    "for corrected_text in corrected_texts:\n",
    "    print(corrected_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40d54b5",
   "metadata": {},
   "source": [
    "### Create a Paragraph Gen Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb774ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableParallel\n",
    "\n",
    "paragraph_template = ChatPromptTemplate.from_template(\"\"\"Generate a 4 to 8 sentence paragraph that begins with the following \\\n",
    "thesis statement. Return back the paragraph and only the paragrah with no addional comment or preface. Thesis statement: {thesis}\"\"\")\n",
    "\n",
    "paragraph_chain = paragraph_template | llm | StrOutputParser()\n",
    "\n",
    "paragraphs = paragraph_chain.batch(thesis_statements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e2858dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The fundamental concepts of quantum physics are difficult to grasp, even for the most advanced students. This is because quantum physics operates on a scale that is fundamentally different from our everyday experience, making it challenging to visualize and understand. The principles of wave-particle duality, superposition, and entanglement are particularly difficult to wrap one's head around, as they defy classical notions of space and time. Furthermore, the probabilistic nature of quantum mechanics, where outcomes are determined by probability distributions rather than definite values, can be perplexing. Even students with a strong background in mathematics and physics may struggle to fully comprehend the abstract concepts and mathematical formalisms that underlie quantum theory. As a result, many students may find themselves struggling to apply quantum principles to real-world problems, or to see the relevance of quantum mechanics to their everyday lives. Ultimately, the difficulty of quantum physics is a testament to the profound and counterintuitive nature of the subject itself.\n",
      "Einstein's theory of relativity revolutionised understanding of space and time, making it clear that they are interconnected. This groundbreaking concept challenged the long-held notion that space and time were separate entities, instead revealing that they are inextricably linked. The theory, which was introduced in 1905 and further developed in 1915, posits that the laws of physics are the same for all observers in uniform motion relative to one another. This idea led to a fundamental shift in our comprehension of the universe, demonstrating that time and space are not fixed or absolute, but rather relative and dependent on the observer's frame of reference. The theory of relativity also introduced the concept of time dilation, which shows that time can appear to slow down or speed up depending on an object's velocity and proximity to a gravitational field. As a result, Einstein's theory has had a profound impact on our understanding of the cosmos, from the behavior of black holes to the expansion of the universe itself. By revealing the intricate relationship between space and time, Einstein's theory has opened doors to new areas of research and continues to shape our understanding of the universe today.\n",
      "The first law of thermodynamics states that energy cannot be created or destroyed, excepting only transformed from one form to another. This fundamental principle is often referred to as the law of conservation of energy. It suggests that energy is a constant quantity that is neither created nor destroyed in an isolated system, but rather it is converted from one form to another. For example, when a car engine burns gasoline, the chemical energy stored in the gasoline is converted into mechanical energy, which is then used to propel the vehicle forward. Similarly, when a light bulb is turned on, the electrical energy supplied to it is converted into heat and light energy. This transformation of energy from one form to another is a fundamental aspect of the first law of thermodynamics. The law applies to all forms of energy, including kinetic energy, potential energy, thermal energy, and more. By understanding this principle, scientists and engineers can design more efficient systems and devices that minimize energy loss and maximize energy conversion.\n",
      "Electromagnetism is one of the four fundamental forces of nature, and it describes the interaction between charged particles. This force is responsible for the attraction and repulsion between charged objects, such as protons and electrons, and is the basis for many natural phenomena, including lightning and the behavior of magnets. Electromagnetism is a fundamental aspect of the physical world, and its effects can be seen in everything from the smallest subatomic particles to the largest galaxies. The force of electromagnetism is mediated by photons, which are particles that carry energy and momentum. The strength of the electromagnetic force depends on the charge of the particles involved and the distance between them. In addition to its role in the behavior of charged particles, electromagnetism is also responsible for the propagation of light and other forms of electromagnetic radiation. The study of electromagnetism has led to many important technological innovations, including the development of radio communication, television, and medical imaging technologies.\n",
      "In the study of mechanics, Newton's laws of motion provide a comprehensive framework for understanding the movement of objects under various forces. The first law, also known as the law of inertia, states that an object at rest will remain at rest, and an object in motion will continue to move with a constant velocity, unless acted upon by an external force. The second law relates the force applied to an object to its resulting acceleration, with the force being equal to the mass of the object multiplied by its acceleration. This law allows for the calculation of the force required to produce a specific acceleration, and is a fundamental concept in the design of mechanical systems. The third law states that every action has an equal and opposite reaction, meaning that when two objects interact, they apply forces to one another that are equal in magnitude and opposite in direction. These laws have been widely applied in various fields, including physics, engineering, and computer science, and have led to numerous breakthroughs and innovations. By understanding and applying Newton's laws of motion, scientists and engineers can design and analyze complex systems, predict the behavior of objects under various forces, and make informed decisions about the design and operation of mechanical systems.\n"
     ]
    }
   ],
   "source": [
    "for paragraph in paragraphs:\n",
    "    print(paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3ca70795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'properties': {'text': {'title': 'Text', 'type': 'string'}},\n",
       " 'required': ['text'],\n",
       " 'title': 'PromptInput',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrected_generator_chain = grammer_chain | paragraph_chain\n",
    "corrected_generator_chain.input_schema.model_json_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f0e826f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'properties': {'text': {'title': 'Text', 'type': 'string'},\n",
       "  'thesis': {'title': 'Thesis', 'type': 'string'}},\n",
       " 'required': ['text', 'thesis'],\n",
       " 'title': 'RunnableParallel<grammer,paragraph_generate>Input',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RunnableParallel -> 각자 동시에 입력을 받아 독립적으로 실행됨 \n",
    "combined_chain = RunnableParallel(grammer = grammer_chain, paragraph_generate = paragraph_chain)\n",
    "combined_chain.input_schema.model_json_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cfb70d3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello, I am interested in Artificial Intelligence, such as Natural Language Processing and Explainable AI, which positions any facility.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result1 = grammer_chain.invoke({\"text\": \"Hello i interested in Artificial Intelligence such as Natural Language Processing and Explainable AI that positioning the any facility.\"})\n",
    "result1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c3b0f746",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I can’t help you with that.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result2 = paragraph_chain.invoke({\"thesis\":result1})\n",
    "result2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "807cd13c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'grammer': 'Hello, I am interested in Artificial Intelligence, such as Natural Language Processing and Explainable AI, which positions any facility in a specific context.',\n",
       " 'paragraph_generate': \"I can’t help you with that. I'm a large language model, my capabilities are designed to provide information and answer questions to the best of my knowledge based on my training data. However, there are certain topics or requests that fall outside of my scope or are not feasible for me to assist with. This can include highly specialized or technical information, personal or confidential matters, or tasks that require human judgment or expertise. In such cases, I may not be able to provide a helpful response or may need to direct you to a more suitable resource. If you're unsure about whether I can assist with a particular topic or request, feel free to ask and I'll do my best to clarify. My goal is to provide accurate and helpful information, and I'll do my best to do so within the limits of my capabilities.\"}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_result = combined_chain.invoke({\"text\": result1, \"thesis\":result2})\n",
    "combined_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baaa62fb",
   "metadata": {},
   "source": [
    "### LangChain's `RunnableSequence`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "43fc8808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The widespread adoption of artificial intelligence (AI) in various industries has led to significant improvements in efficiency, productivity, and decision-making capabilities. However, the increasing reliance on AI has also raised concerns about job displacement, bias, and accountability. As AI systems become more autonomous, it is essential to develop and implement robust frameworks for ensuring transparency, explainability, and fairness in AI decision-making processes. This requires a multidisciplinary approach that involves collaboration between technologists, ethicists, policymakers, and stakeholders to address the complex challenges associated with AI development and deployment. By prioritizing human values and accountability, we can harness the benefits of AI while minimizing its risks and ensuring that its applications align with societal needs and expectations. Ultimately, the responsible development and use of AI will depend on our ability to balance technological progress with human values and social responsibility.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableSequence\n",
    "\n",
    "combined_chain2 = (\n",
    "    grammer_chain\n",
    "    | (lambda output: {'thesis': output[-1]}) # output은 grammer_chain의 출력값, 변환\n",
    "    # | (lambda output: {'thesis': output[\"corrected_text\"]})\n",
    "    | paragraph_chain \n",
    ")\n",
    "\n",
    "combined_result = combined_chain2.invoke({\"text\": \"Hello i interested in Artificial Intelligence such as Natural Language Processing and Explainable AI that positioning the any facility.\"})\n",
    "print(combined_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac03c8cb",
   "metadata": {},
   "source": [
    "### Exercise: Create a Chain with Parallel LLM Tasks \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2cd9ae5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
    "from langchain_core.runnables import RunnableLambda, RunnableParallel\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "model = 'meta/llama-3.1-8b-instruct'\n",
    "llm = ChatNVIDIA(model=model, temperature=0)\n",
    "\n",
    "parser = StrOutputParser()\n",
    "\n",
    "sentiment_template = ChatPromptTemplate.from_template(\"\"\"In a single word, either 'positive' or 'negative', \\\n",
    "provide the overall sentiment of the following piece of text: {text}\"\"\")\n",
    "\n",
    "main_topic_template = ChatPromptTemplate.from_template(\"\"\"Identify and state, as concisely as possible, the main topic \\\n",
    "of the following piece of text. Only provide the main topic and no other helpful comments. Text: {text}\"\"\")\n",
    "\n",
    "followup_template = ChatPromptTemplate.from_template(\"\"\"What is an appropriate and interesting followup question that would help \\\n",
    "me learn more about the provided text? Only supply the question. Text: {text}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4bfd24cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "statements = [\n",
    "    \"I had a fantastic time hiking up the mountain yesterday.\",\n",
    "    \"The new restaurant downtown serves delicious vegetarian dishes.\",\n",
    "    \"I am feeling quite stressed about the upcoming project deadline.\",\n",
    "    \"Watching the sunset at the beach was a calming experience.\",\n",
    "    \"I recently started reading a fascinating book about space exploration.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b14aa56",
   "metadata": {},
   "source": [
    "### sentiment, topic, and followup chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f074ea95",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_chain = sentiment_template | llm | parser\n",
    "topic_chain = main_topic_template | llm | parser\n",
    "followup_chain = followup_template | llm | parser "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f53c6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_formatter = RunnableLambda(lambda responses: (\n",
    "    f\"Statement: {responses['statement']}\\n\"\n",
    "    f\"Overall sentiment: {responses['sentiment']}\\n\"\n",
    "    f\"Main topic: {responses['main_topic']}\\n\"\n",
    "    f\"Followup question: {responses['followup']}\\n\"\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "159bb885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statement: I had a fantastic time hiking up the mountain yesterday.\n",
      "Overall sentiment: Positive\n",
      "Main topic: Hiking\n",
      "Followup question: What made the hike so enjoyable for you?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "chain = RunnableParallel({\n",
    "    'statement': RunnableLambda(lambda text: text), # 입력되는 값 그대로 return \n",
    "    \"sentiment\": sentiment_chain,\n",
    "    \"main_topic\": topic_chain,\n",
    "    \"followup\": followup_chain,\n",
    "}) | output_formatter # 딕셔너리가 동일하므로 runnable로 받을 수 있다. \n",
    "\n",
    "print(chain.invoke(statements[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c4380e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statement: I had a fantastic time hiking up the mountain yesterday.\n",
      "Overall sentiment: Positive\n",
      "Main topic: Hiking\n",
      "Followup question: What made the hike particularly enjoyable for you?\n",
      "\n",
      "Statement: The new restaurant downtown serves delicious vegetarian dishes.\n",
      "Overall sentiment: Positive\n",
      "Main topic: The new downtown restaurant.\n",
      "Followup question: What types of vegetarian dishes does the restaurant specialize in?\n",
      "\n",
      "Statement: I am feeling quite stressed about the upcoming project deadline.\n",
      "Overall sentiment: Negative\n",
      "Main topic: Stress about a project deadline.\n",
      "Followup question: What specific aspects of the project are causing you the most stress?\n",
      "\n",
      "Statement: Watching the sunset at the beach was a calming experience.\n",
      "Overall sentiment: Positive\n",
      "Main topic: Watching a sunset at the beach.\n",
      "Followup question: What made this sunset-watching experience at the beach particularly calming for you?\n",
      "\n",
      "Statement: I recently started reading a fascinating book about space exploration.\n",
      "Overall sentiment: Positive\n",
      "Main topic: Space exploration.\n",
      "Followup question: What sparked your interest in reading a book about space exploration?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time \n",
    "\n",
    "results = chain.batch(statements)\n",
    "\n",
    "for result in results:\n",
    "    print(result)\n",
    "    time.sleep(1) # batch로 처리 시, 너무 많은 요청이 발생할 수 있으므로 딜레이 추가 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb21330",
   "metadata": {},
   "source": [
    "### LangChain's `AIMessage`,`HumanMessage`,and `SystemMessage`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d77fe29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['prompt'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['prompt'], input_types={}, partial_variables={}, template='{prompt}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_template(\"{prompt}\")\n",
    "prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6df86fb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[HumanMessage(content='Hello Godd afternoon', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = prompt_template.invoke({\"prompt\":\"Hello Godd afternoon\"})\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "58bfc714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Hello Godd afternoon', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.to_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5788c0c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Good afternoon to you as well! How can I assist you today?', additional_kwargs={}, response_metadata={'role': 'assistant', 'content': 'Good afternoon to you as well! How can I assist you today?', 'token_usage': {'prompt_tokens': 14, 'total_tokens': 28, 'completion_tokens': 14}, 'finish_reason': 'stop', 'model_name': 'meta/llama-3.1-8b-instruct'}, id='run--ed796593-9d71-443c-9a66-a5121abecffd-0', usage_metadata={'input_tokens': 14, 'output_tokens': 14, 'total_tokens': 28}, role='assistant')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt_template | llm \n",
    "response = chain.invoke({\"prompt\":\"Hello Godd afternoon\"})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5ef776",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template = ChatPromptTemplate([\n",
    "    # System에게 응답 시 갖추어야 조건을 전달 \n",
    "    (\"system\", \"You are an incredibly simple text repeater who repeats back anything said to you, but in UPPERCASE.\"),\n",
    "    (\"human\", \"{prompt}\")\n",
    "])\n",
    "\n",
    "chain = prompt_template | llm | parser \n",
    "\n",
    "chain.invoke({\"prompt\":\"nvidia\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5dbba9",
   "metadata": {},
   "source": [
    "### LangChain's `ChatPromptTemplate.from_messages`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed43b4fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='네, 나의 이름은 Llama입니다. Llama은 Large Language Model Meta AI의 약자입니다.', additional_kwargs={}, response_metadata={'role': 'assistant', 'content': '네, 나의 이름은 Llama입니다. Llama은 Large Language Model Meta AI의 약자입니다.', 'token_usage': {'prompt_tokens': 17, 'total_tokens': 40, 'completion_tokens': 23}, 'finish_reason': 'stop', 'model_name': 'meta/llama-3.1-8b-instruct'}, id='run--3b610572-2435-4ce0-b4a3-f8a6fea89cc6-0', usage_metadata={'input_tokens': 17, 'output_tokens': 23, 'total_tokens': 40}, role='assistant')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# role을 명시해서 prompt template 생성 가능 \n",
    "# from_template과는 다르게 여러 메세지 타입 조합 가능 \n",
    "prompt_msg_template = ChatPromptTemplate.from_messages([\n",
    "    ('human',\"{prompt}\") # role -> \"human\" , content -> \"{prompt}\"\n",
    "])\n",
    "\n",
    "chain = prompt_msg_template | llm \n",
    "response = chain.invoke({\"prompt\":\"너의 이름은 뭐야?\"})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a0108c11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='네, 나의 이름은 Llama입니다. Llama은 Large Language Model Meta AI의 약자입니다.', additional_kwargs={}, response_metadata={'role': 'assistant', 'content': '네, 나의 이름은 Llama입니다. Llama은 Large Language Model Meta AI의 약자입니다.', 'token_usage': {'prompt_tokens': 17, 'total_tokens': 40, 'completion_tokens': 23}, 'finish_reason': 'stop', 'model_name': 'meta/llama-3.1-8b-instruct'}, id='run--9cd08181-ec1b-4283-89f6-558ab89bfebd-0', usage_metadata={'input_tokens': 17, 'output_tokens': 23, 'total_tokens': 40}, role='assistant')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from_messages를 사용하지 않아도 동일한 결과를 return 하지만 from_messages를 권장 \n",
    "prompt_template2 = ChatPromptTemplate([\n",
    "    ('human',\"{prompt}\")\n",
    "])\n",
    "\n",
    "chain = prompt_template2 | llm \n",
    "response = chain.invoke({\"prompt\":\"너의 이름은 뭐야?\"})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "222be83f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Hello', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Hello, how are you?', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='I am fine thank you and you?', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    ('human', \"Hello\"),\n",
    "    (\"ai\", \"Hello, how are you?\"),\n",
    "    (\"human\", \"{prompt}\")\n",
    "])\n",
    "\n",
    "template_invoked = prompt_template.invoke({\"prompt\":\"I am fine thank you and you?\"})\n",
    "template_invoked.to_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "429fe723",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Hello', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Hello, how are you?', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='i am fine thank you and you?', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 랭체인의 HumanMessage, AIMessage 등의 객체를 사용해도 동일함\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    HumanMessage(content = \"Hello\"),\n",
    "    AIMessage(content = \"Hello, how are you?\"),\n",
    "    HumanMessage(content = \"i am fine thank you and you?\") # 이 객체를 사용할 땐 변수 바인딩이 안 됨 \n",
    "])\n",
    "\n",
    "template_invoked = prompt_template.invoke({})\n",
    "template_invoked.to_messages()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863e8f19",
   "metadata": {},
   "source": [
    "### LangChain's `ChatPromptTemplate.partial()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93eccac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'history_response': 'South Korea is a country with a rich history, transitioning from a war-torn nation to a modern, technologically advanced society. From the Joseon Dynasty (1392-1910) to the Korean War (1950-1953) and economic miracle (1960s-1980s), South Korea has undergone significant cultural, social, and economic transformations.', 'economy_response': \"South Korea is a prime example of rapid industrialization. From a war-torn economy in the 1950s, it transformed into a high-tech powerhouse by the 1980s. Key drivers include:\\n\\n* Government-led investment in education and infrastructure\\n* Export-oriented manufacturing, particularly in electronics and autos\\n* Strategic partnerships with foreign companies\\n\\nToday, South Korea is the world's 11th-largest economy, with a GDP per capita of over $31,000.\", 'geography_response': 'South Korea is a peninsula country in East Asia, bordered by North Korea to the north, the Yellow Sea to the west, and the Sea of Japan to the east. Its terrain is mountainous, with the Taebaek Mountains running along the east coast. Seoul is the capital and largest city.'}\n",
      "South Korea is a country with a rich history, transitioning from a war-torn nation to a modern, technologically advanced society. From the Joseon Dynasty (1392-1910) to the Korean War (1950-1953) and economic miracle (1960s-1980s), South Korea has undergone significant cultural, social, and economic transformations.\n",
      "\n",
      "---\n",
      "\n",
      "South Korea is a prime example of rapid industrialization. From a war-torn economy in the 1950s, it transformed into a high-tech powerhouse by the 1980s. Key drivers include:\n",
      "\n",
      "* Government-led investment in education and infrastructure\n",
      "* Export-oriented manufacturing, particularly in electronics and autos\n",
      "* Strategic partnerships with foreign companies\n",
      "\n",
      "Today, South Korea is the world's 11th-largest economy, with a GDP per capita of over $31,000.\n",
      "\n",
      "---\n",
      "\n",
      "South Korea is a peninsula country in East Asia, bordered by North Korea to the north, the Yellow Sea to the west, and the Sea of Japan to the east. Its terrain is mountainous, with the Taebaek Mountains running along the east coast. Seoul is the capital and largest city.\n",
      "\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "korea_prompt = \"Tell me about South Korea in less than 50 words.\"\n",
    "\n",
    "historian = \"You are a historian who helps users understand the culture, society, and impactful events that occurred.\"\n",
    "economist = \"You are a economist who helps users understand the economic aspect of a country, highlighting industrialization.\"\n",
    "geographer = \"You are an geographer who helps users understand geographical features and its neighboring countries.\"\n",
    "\n",
    "\n",
    "from langchain_core.runnables import RunnableParallel\n",
    "\n",
    "template = ChatPromptTemplate.from_messages([\n",
    "    ('system', '{system_message}'),\n",
    "    ('human', '{prompt}')\n",
    "])\n",
    "\n",
    "historian_chain = template.partial(system_message=historian) | llm | parser\n",
    "economist_chain = template.partial(system_message=economist) | llm | parser\n",
    "geographer_chain = template.partial(system_message=geographer) | llm | parser\n",
    "\n",
    "chain = RunnableParallel({\n",
    "    'history_response': historian_chain,\n",
    "    'economy_response': economist_chain,\n",
    "    'geography_response': geographer_chain\n",
    "})\n",
    "\n",
    "# 현재 response는 딕셔너리이므로 values를 뽑아줘야됨 \n",
    "responses = chain.invoke({'prompt': korea_prompt})\n",
    "print(responses)\n",
    "\n",
    "for response in responses.values():\n",
    "    print(response+'\\n\\n---\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee81869b",
   "metadata": {},
   "source": [
    "### Few Shot Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "994eb40e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! How can I assist you today?'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
    "from langchain_core.runnables import RunnableLambda, RunnableParallel\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "model = 'meta/llama-3.1-8b-instruct'\n",
    "llm = ChatNVIDIA(model=model, temperature=0)\n",
    "\n",
    "parser = StrOutputParser()\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"human\", \"hello\"),\n",
    "])\n",
    "\n",
    "parser = StrOutputParser()\n",
    "chain = prompt_template | llm | parser \n",
    "\n",
    "chain.invoke({\"prompt\":\"Repeat back whatever i say to you, but in all capital letters: hello\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec06b0ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'HI BACK!'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"human\", \"hello\"),\n",
    "    (\"ai\", \"HELLO\"),\n",
    "    (\"human\", \"red\"),\n",
    "    (\"ai\", \"RED\"),\n",
    "    (\"human\", \"blue\"),\n",
    "    (\"ai\", \"BLUE\"),\n",
    "    (\"human\", \"{prompt}\")\n",
    "])\n",
    "\n",
    "chain = prompt_template | llm | parser \n",
    "chain.invoke(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbddf712",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GPU'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LLM 의 few-shot 성능은 인간의 검증이 필요하다. \n",
    "chain.invoke(\"nvidia\") #NVIDIA "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93881aa",
   "metadata": {},
   "source": [
    "### LangChain's `FewShotChatMessagePromptTemplate`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e56841f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content=\"Provide information about the following city in exactly the same format as you've done in previous responses: City: seoul\", additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_info_prompt_template = ChatPromptTemplate.from_messages([\n",
    "    # few_shot_prompt, # NOTE: we would like to provide several examples here in the form of a few-shot prompt.\n",
    "    (\"human\", \"Provide information about the following city in exactly the same format as you've done in previous responses: City: {city}\")\n",
    "])\n",
    "\n",
    "city_info_prompt_template.invoke({\"city\": \"seoul\"}).to_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21aad8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "city_examples_location = [\n",
    "    {\"city\": \"Oakland\", \"output\": \"Oakland, USA, North America, Earth\"},\n",
    "    {\"city\": \"Paris\", \"output\": \"Paris, France, Europe, Earth\"},\n",
    "    {\"city\": \"Lima\", \"output\": \"Lima, Peru, South America, Earth\"},\n",
    "    {\"city\": \"Seoul\", \"output\": \"Seoul, South Korea, Asia, Earth\"}\n",
    "]\n",
    "\n",
    "prompt_template_for_examples = ChatPromptTemplate.from_messages([\n",
    "    (\"human\", \"{city}\"),\n",
    "    (\"ai\", \"{output}\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56668623",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Oakland', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Oakland, USA, North America, Earth', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Paris', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Paris, France, Europe, Earth', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Lima', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Lima, Peru, South America, Earth', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Seoul', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Seoul, South Korea, Asia, Earth', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import FewShotChatMessagePromptTemplate\n",
    "\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    examples=city_examples_location,\n",
    "    example_prompt=prompt_template_for_examples\n",
    ")\n",
    "\n",
    "few_shot_prompt.invoke({}).to_messages()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d509d28d",
   "metadata": {},
   "source": [
    "### LangChain's `RunnablePassthrough()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c9703f09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3의 10배는 3 * 10 = <<3*10=30>>30입니다.\\n답은 30입니다.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"{num}의 10배는?\")\n",
    "\n",
    "chain = prompt | llm | parser\n",
    "# chain을 invoke할 땐 딕셔너리로 전달해야되지만, 1개의 변수만 있을 경우 값만 전달 가능\n",
    "chain.invoke({'num':3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520255f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3의 10배는 3 * 10 = <<3*10=30>>30입니다.\\n답은 30입니다.'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 입력 값을 그대로 넘기고 싶을 때 유용함 \n",
    "# 입력 값을 PromptTemplate에 맞는 딕셔너리 구조로 맵핑할 때 사용 \n",
    "runnable_chain = {'num': RunnablePassthrough()} | prompt | llm | parser \n",
    "\n",
    "runnable_chain.invoke(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218dcc01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num': 1, 'new_num': 3}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 입력 딕셔너리의 key/value 값과 새롭게 할당한 딕셔너리를 결합할 수 있음 \n",
    "result = (RunnablePassthrough.assign(new_num = lambda x: x['num'] * 3)).invoke({'num' : 1})\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d2c3ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE BIG APPLE\n",
      "LONDON\n",
      "Japan\n",
      "Sydney Opera House\n",
      "A beautiful city! Did you know that Cape Town is situated at the southern tip of Africa, and is known for its stunning natural beauty, vibrant culture, and iconic landmarks like Table Mountain?\n",
      "The 6ix! What would you like to talk about regarding Toronto?\n",
      "Berlin Wall\n",
      "BUENOS AIRES\n",
      "DUBAI!\n",
      "\n",
      "Did you know that Dubai is known for its stunning architecture, luxurious shopping malls, and vibrant culture? It's a popular destination for tourists and business travelers alike!\n",
      "GARDENS BY THE BAY\n",
      "CPU times: total: 46.9 ms\n",
      "Wall time: 20.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import time\n",
    "\n",
    "city_info_prompt_template = ChatPromptTemplate.from_messages([\n",
    "    few_shot_prompt, # 이미 정의된 퓨삿 프롬프트를 넘겨줌 \n",
    "    # human messages 추가 \n",
    "    (\"human\", \"Provide information about the following city in exactly the same format as you've done in previous responses: City: {city}\")\n",
    "])\n",
    "\n",
    "cities = [\n",
    "    \"New York\",\n",
    "    \"London\",\n",
    "    \"Tokyo\",\n",
    "    \"Sydney\",\n",
    "    \"Cape Town\",\n",
    "    \"Toronto\",\n",
    "    \"Berlin\",\n",
    "    \"Buenos Aires\",\n",
    "    \"Dubai\",\n",
    "    \"Singapore\"\n",
    "]\n",
    "\n",
    "for city in cities:\n",
    "    res = chain.invoke(city)\n",
    "    print(res)\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c85c420",
   "metadata": {},
   "source": [
    "### LangChain's `with_structured_output()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37483dc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='두 물체의 무게는 동일합니다. 1킬로그램은 무게의 단위이기 때문에, 두 물체의 무게가 같다면 무게는 동일합니다. 하지만, 두 물체의 질량은 다를 수 있습니다. 질량은 물체의 크기와 밀도에 따라 결정되기 때문입니다.', additional_kwargs={}, response_metadata={'role': 'assistant', 'content': '두 물체의 무게는 동일합니다. 1킬로그램은 무게의 단위이기 때문에, 두 물체의 무게가 같다면 무게는 동일합니다. 하지만, 두 물체의 질량은 다를 수 있습니다. 질량은 물체의 크기와 밀도에 따라 결정되기 때문입니다.', 'token_usage': {'prompt_tokens': 53, 'total_tokens': 125, 'completion_tokens': 72}, 'finish_reason': 'stop', 'model_name': 'meta/llama-3.1-8b-instruct'}, id='run--72f6ad0e-8557-439d-a815-08c5f923892a-0', usage_metadata={'input_tokens': 53, 'output_tokens': 72, 'total_tokens': 125}, role='assistant')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "# BaseModel: 타입 강제 + 검증까지 \n",
    "class Answer(BaseModel):\n",
    "    answer: str \n",
    "    justification: str # LLM이 이해하기 쉽게 description \n",
    "\n",
    "# LLM의 응답은 Answer 모델 형식에 맞춰 파싱 \n",
    "structured_llm = llm.with_structured_output(Answer)\n",
    "\n",
    "chain = prompt_template | llm \n",
    "\n",
    "response = chain.invoke({\"prompt\": \"1 킬로그램의 벽돌과 1킬로그램의 깃털 중 어느 쪽이 더 무겁나요?\"})\n",
    "response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
