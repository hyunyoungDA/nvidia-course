{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f59fe495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langgraph\n",
      "  Downloading langgraph-0.5.4-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: langchain-core>=0.1 in c:\\users\\user\\anaconda3\\envs\\ragenv\\lib\\site-packages (from langgraph) (0.3.69)\n",
      "Collecting langgraph-checkpoint<3.0.0,>=2.1.0 (from langgraph)\n",
      "  Downloading langgraph_checkpoint-2.1.1-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting langgraph-prebuilt<0.6.0,>=0.5.0 (from langgraph)\n",
      "  Downloading langgraph_prebuilt-0.5.2-py3-none-any.whl.metadata (4.5 kB)\n",
      "Collecting langgraph-sdk<0.2.0,>=0.1.42 (from langgraph)\n",
      "  Downloading langgraph_sdk-0.1.74-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in c:\\users\\user\\anaconda3\\envs\\ragenv\\lib\\site-packages (from langgraph) (2.11.7)\n",
      "Collecting xxhash>=3.5.0 (from langgraph)\n",
      "  Using cached xxhash-3.5.0-cp310-cp310-win_amd64.whl.metadata (13 kB)\n",
      "Collecting ormsgpack>=1.10.0 (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph)\n",
      "  Downloading ormsgpack-1.10.0-cp310-cp310-win_amd64.whl.metadata (44 kB)\n",
      "Requirement already satisfied: httpx>=0.25.2 in c:\\users\\user\\anaconda3\\envs\\ragenv\\lib\\site-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in c:\\users\\user\\anaconda3\\envs\\ragenv\\lib\\site-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.11.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\user\\anaconda3\\envs\\ragenv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (4.9.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\user\\anaconda3\\envs\\ragenv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (2025.7.14)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\user\\anaconda3\\envs\\ragenv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\user\\anaconda3\\envs\\ragenv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\user\\anaconda3\\envs\\ragenv\\lib\\site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.16.0)\n",
      "Requirement already satisfied: langsmith>=0.3.45 in c:\\users\\user\\anaconda3\\envs\\ragenv\\lib\\site-packages (from langchain-core>=0.1->langgraph) (0.4.8)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\user\\anaconda3\\envs\\ragenv\\lib\\site-packages (from langchain-core>=0.1->langgraph) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\user\\anaconda3\\envs\\ragenv\\lib\\site-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\user\\anaconda3\\envs\\ragenv\\lib\\site-packages (from langchain-core>=0.1->langgraph) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\user\\anaconda3\\envs\\ragenv\\lib\\site-packages (from langchain-core>=0.1->langgraph) (4.14.0)\n",
      "Requirement already satisfied: packaging>=23.2 in c:\\users\\user\\anaconda3\\envs\\ragenv\\lib\\site-packages (from langchain-core>=0.1->langgraph) (25.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\user\\anaconda3\\envs\\ragenv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.1->langgraph) (3.0.0)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\user\\anaconda3\\envs\\ragenv\\lib\\site-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (2.32.4)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\user\\anaconda3\\envs\\ragenv\\lib\\site-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\user\\anaconda3\\envs\\ragenv\\lib\\site-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\user\\anaconda3\\envs\\ragenv\\lib\\site-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\user\\anaconda3\\envs\\ragenv\\lib\\site-packages (from pydantic>=2.7.4->langgraph) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\user\\anaconda3\\envs\\ragenv\\lib\\site-packages (from pydantic>=2.7.4->langgraph) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\user\\anaconda3\\envs\\ragenv\\lib\\site-packages (from requests<3,>=2->langsmith>=0.3.45->langchain-core>=0.1->langgraph) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\anaconda3\\envs\\ragenv\\lib\\site-packages (from requests<3,>=2->langsmith>=0.3.45->langchain-core>=0.1->langgraph) (2.5.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\user\\anaconda3\\envs\\ragenv\\lib\\site-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\user\\anaconda3\\envs\\ragenv\\lib\\site-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.3.1)\n",
      "Downloading langgraph-0.5.4-py3-none-any.whl (143 kB)\n",
      "Downloading langgraph_checkpoint-2.1.1-py3-none-any.whl (43 kB)\n",
      "Downloading langgraph_prebuilt-0.5.2-py3-none-any.whl (23 kB)\n",
      "Downloading langgraph_sdk-0.1.74-py3-none-any.whl (50 kB)\n",
      "Downloading ormsgpack-1.10.0-cp310-cp310-win_amd64.whl (121 kB)\n",
      "Using cached xxhash-3.5.0-cp310-cp310-win_amd64.whl (30 kB)\n",
      "Installing collected packages: xxhash, ormsgpack, langgraph-sdk, langgraph-checkpoint, langgraph-prebuilt, langgraph\n",
      "\n",
      "   -------------------------- ------------- 4/6 [langgraph-prebuilt]\n",
      "   --------------------------------- ------ 5/6 [langgraph]\n",
      "   ---------------------------------------- 6/6 [langgraph]\n",
      "\n",
      "Successfully installed langgraph-0.5.4 langgraph-checkpoint-2.1.1 langgraph-prebuilt-0.5.2 langgraph-sdk-0.1.74 ormsgpack-1.10.0 xxhash-3.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install langgraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4ada21",
   "metadata": {},
   "source": [
    "## TypedDict\n",
    "- `dict`에서는 런타임에 타입 검사를 하지 않는 반면에 `TypedDict`은 정적 타입 검사를 통해 오류를 미리 잡을 수 있음\n",
    "- `TypedDict`는 각 키에 대해 구체적인 타입을 지정할 수 있고 키를 추가하거나 제거하는 것에 엄격하여 오류 발생 가능 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88702c58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'hyun', 'age': '30', 'hobby': 'soccer'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Dict, TypedDict \n",
    "\n",
    "sample_dict: Dict[str, str] = {\n",
    "    \"name\" : \"hyun\",\n",
    "    \"age\" : \"30\",\n",
    "    \"hobby\" : \"soccer\",\n",
    "}\n",
    "\n",
    "sample_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7c59b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'hyun', 'age': 35, 'hobby': 'soccer', 'job': 'AI engineer'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_dict['age'] = 35 # string에서 integer로 값을 변경하여도 오류 X; TypedDict은 오류 발생 \n",
    "sample_dict['job'] = \"AI engineer\"\n",
    "\n",
    "sample_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5644c4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'young', 'age': 25, 'hobby': 'basketball'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Person(TypedDict):\n",
    "    # 각 키에 대해 구체적인 타입 지정 가능 \n",
    "    name: str\n",
    "    age: int\n",
    "    hobbty: str \n",
    "    \n",
    "typed_dict: Person = {\"name\": \"young\", \"age\" : 25, \"hobby\" : \"basketball\"}\n",
    "typed_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509d62c0",
   "metadata": {},
   "source": [
    "## Annotated \n",
    "\n",
    "타입 힌트에 메타데이터를 추가할 수 있게 하여 코드에 대한 추가 설명을 타입 힌트에 직접 포함 가능\n",
    "\n",
    "- `name: Annotated[str, \"이름\"]`\n",
    "- `age: Annotated[int, '나이']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c40ee67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "name: Annotated[str, \"사용자 이름\"]\n",
    "age: Annotated[int, \"사용자 나이 (10 ~ 150)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8744b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pydantic과 결합하여 사용 가능 \n",
    "from pydantic import Field, BaseModel, ValidationError\n",
    "\n",
    "class Employee(BaseModel):\n",
    "    id: Annotated[int, Field(..., description = \"직원 ID\")]\n",
    "    name: Annotated[str, Field(..., min_length=3, max_length=50, description=\"이름\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05374a6d",
   "metadata": {},
   "source": [
    "## StateGraph 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d252eabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, TypedDict\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import StateGraph, START, END, add_messages\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "import os\n",
    "\n",
    "load_dotenv(\"../../.env\")\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "class State(TypedDict):\n",
    "    # add_messages는 리듀서 함수인데, 기존 메모리에 새 메시지를 추가하도록 지시\n",
    "    # 주석이 없는 키는 갱신마다 가장 최근의 값이 저장됨 \n",
    "    messages: Annotated[list, add_messages]\n",
    "    \n",
    "builder = StateGraph(State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71f1cbc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x1f70ad9a470>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ChatOpenAI(\n",
    "    model = \"gpt-4o-mini\",\n",
    "    temperature = 0.7\n",
    ")\n",
    "\n",
    "# 챗봇 노드 정의 및 추가 \n",
    "def chatbot(state: State):\n",
    "    answer = model.invoke(state['messages'])\n",
    "    return {\"messages\": [answer]}\n",
    "\n",
    "# 노드 이름, 함수 혹은 callable 객체를 인자로 받아 노드 추가 \n",
    "builder.add_node('chatbot', chatbot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ba83d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 엣지를 추가하여 작업 시작 위치와 종료 위치 전달 \n",
    "builder.add_edge(START, 'chatbot')\n",
    "builder.add_edge('chatbot', END)\n",
    "\n",
    "graph = builder.compile() # 컴파일하여 Runnable 객체로 전환 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcc878b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x000001F70A9D1780>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c10e51c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: 서울에는 다양한 맛집이 많이 있지만, 아래는 유명한 맛집 TOP 10을 추천해 드립니다. 각 식당은 고유의 매력을 가지고 있으니 참고하시기 바랍니다.\n",
      "\n",
      "1. **광장시장** - 전통 시장으로, 다양한 한국 길거리 음식을 맛볼 수 있습니다. 특히 빈대떡과 마약김밥이 유명합니다.\n",
      "\n",
      "2. **삼청동 수제비** - 쫄깃한 수제비와 시원한 국물이 인기인 곳으로, 아늑한 분위기에서 식사를 즐길 수 있습니다.\n",
      "\n",
      "3. **명동교자** - 칼국수와 만두가 유명한 맛집으로, 깊고 진한 국물 맛이 일품입니다.\n",
      "\n",
      "4. **갈비집** - 한우 갈비가 유명한 식당으로, 고품질의 고기를 즐길 수 있는 곳입니다. 예약을 권장합니다.\n",
      "\n",
      "5. **이태원부대찌개** - 부대찌개가 유명한 곳으로, 푸짐한 양과 맛있는 국물로 사랑받고 있습니다.\n",
      "\n",
      "6. **토속촌 삼계탕** - 전통 삼계탕 전문점으로, 건강한 한 끼를 원하신다면 추천드립니다.\n",
      "\n",
      "7. **부촌수제비** - 수제비와 함께 다양한 찌개를 제공하는 곳으로, 푸짐한 양과 맛이 특징입니다.\n",
      "\n",
      "8. **오장동 함흥냉면** - 함흥냉면이 유명한 곳으로, 쫄깃한 면발과 시원한 육수가 일품입니다.\n",
      "\n",
      "9. **김밥천국** - 저렴하면서도 맛있는 김밥을 즐길 수 있는 곳으로, 다양한 메뉴가 있습니다.\n",
      "\n",
      "10. **홍대 소고기 뚝배기** - 고소한 소고기 뚝배기와 함께 밥을 즐길 수 있는 맛집으로, 친구들과 함께 가기 좋은 곳입니다.\n",
      "\n",
      "각 맛집은 방문 시 대기 시간이 있을 수 있으니 미리 확인하시고 가시는 것을 추천드립니다. 맛있는 식사 되세요!\n"
     ]
    }
   ],
   "source": [
    "question = \"서울의 유명한 맛집 TOP 10 추천해줘\"\n",
    "\n",
    "# 그래프 이벤트 스트리밍\n",
    "for event in graph.stream({\"messages\": [(\"user\", question)]}):\n",
    "    # 이벤트 값 출력\n",
    "    for value in event.values():\n",
    "        print(\"Assistant:\", value[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b350365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕하세요! 어떻게 도와드릴까요?\n"
     ]
    }
   ],
   "source": [
    "input_ = {'messages':[HumanMessage('안녕하세요~!')]}\n",
    "\n",
    "for chunk in graph.stream(input_):\n",
    "    print(chunk['chatbot']['messages'][0].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d828ee",
   "metadata": {},
   "source": [
    "### StateGraph에 메모리 기능 추가\n",
    "\n",
    "- `thread`: 랭그래프에서는 특정 상호작용 기록을 각 사용자별 thread에 포함하여 기록한다. 따라서 여러 사용자가 혼동 없이 동시에 독자적인 대화를 진행할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e6f5857",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "# 이렇게 하면 각 단계가 종료될때마다 state가 기록되어서 최초 실행 이후의 모든ㄷ 호출은 백지 상태로 시작하지 않음\n",
    "graph = builder.compile(checkpointer=MemorySaver())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "475eab58",
   "metadata": {},
   "outputs": [],
   "source": [
    "thread1 = {'configurable': {'thread_id' : 1}}\n",
    "\n",
    "result_1 = graph.invoke({\n",
    "    \"messages\" : [HumanMessage(\"안녕하세요, 저는 Hyun 입니다~\")]}, thread1)\n",
    "\n",
    "result_2 = graph.invoke({\n",
    "    \"messages\": [HumanMessage('제 이름이 뭐죠?')]}, thread1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "95b3d277",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='안녕하세요, 저는 Hyun 입니다~', additional_kwargs={}, response_metadata={}, id='bd84069f-c0b1-4f16-adb1-83b0fd93946a'),\n",
       "  AIMessage(content='안녕하세요, Hyun님! 어떻게 도와드릴까요?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 15, 'total_tokens': 29, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'id': 'chatcmpl-ByCUc5m8cHDRJk2IiGojWpBkPv95c', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--3f1ab6c4-a11b-4579-967e-d9e7dbd2d405-0', usage_metadata={'input_tokens': 15, 'output_tokens': 14, 'total_tokens': 29, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dcd7638c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='안녕하세요, 저는 Hyun 입니다~', additional_kwargs={}, response_metadata={}, id='bd84069f-c0b1-4f16-adb1-83b0fd93946a'),\n",
       "  AIMessage(content='안녕하세요, Hyun님! 어떻게 도와드릴까요?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 15, 'total_tokens': 29, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'id': 'chatcmpl-ByCUc5m8cHDRJk2IiGojWpBkPv95c', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--3f1ab6c4-a11b-4579-967e-d9e7dbd2d405-0', usage_metadata={'input_tokens': 15, 'output_tokens': 14, 'total_tokens': 29, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  HumanMessage(content='제 이름이 뭐죠?', additional_kwargs={}, response_metadata={}, id='bd4c355d-2264-4315-9ffe-272243702cde'),\n",
       "  AIMessage(content='당신의 이름은 Hyun입니다! 다른 질문이 있으신가요?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 43, 'total_tokens': 60, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'id': 'chatcmpl-ByCUdjTPPsKExVgETUYaGnJWJ9DXu', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--36750e5a-6795-4079-b6ca-d34a6ced5778-0', usage_metadata={'input_tokens': 43, 'output_tokens': 17, 'total_tokens': 60, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "294dff0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={'messages': [HumanMessage(content='안녕하세요, 저는 Hyun 입니다~', additional_kwargs={}, response_metadata={}, id='494890ad-18ff-48a6-8764-5a832e792ce7'), AIMessage(content='안녕하세요, Hyun님! 어떻게 도와드릴까요?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 15, 'total_tokens': 29, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'id': 'chatcmpl-ByBuecd4biy6hmAGa6W5wcgCjrAnX', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--6f8fd5ca-0ddf-4f7e-a678-2406b3936bbf-0', usage_metadata={'input_tokens': 15, 'output_tokens': 14, 'total_tokens': 29, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), HumanMessage(content='제 이름이 뭐죠?', additional_kwargs={}, response_metadata={}, id='24a186bc-4285-4f90-a192-a3f22d844887'), AIMessage(content='당신의 이름은 Hyun입니다! 다른 질문이 있으신가요?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 43, 'total_tokens': 60, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'id': 'chatcmpl-ByBue5SxnCs163twPHgw7eoOcLEQX', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--d3831e28-db7f-4c03-a57c-a65649c2a917-0', usage_metadata={'input_tokens': 43, 'output_tokens': 17, 'total_tokens': 60, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f06b7e8-d9c5-6e23-8004-07ddda9f3671'}}, metadata={'source': 'loop', 'step': 4, 'parents': {}}, created_at='2025-07-28T06:46:13.437187+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f06b7e8-cf52-603b-8003-c88c5d10806f'}}, tasks=(), interrupts=())"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.get_state(thread1) # 상태 확인 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc4510f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configurable': {'thread_id': '1',\n",
       "  'checkpoint_ns': '',\n",
       "  'checkpoint_id': '1f06b7f1-00d8-6167-8005-0ffe0b547867'}}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 상태 업데이트 가능 \n",
    "graph.update_state(thread1, {'messages': HumanMessage('전 LLM에 관심이 많습니다')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "69956c6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={'messages': [HumanMessage(content='안녕하세요, 저는 Hyun 입니다~', additional_kwargs={}, response_metadata={}, id='494890ad-18ff-48a6-8764-5a832e792ce7'), AIMessage(content='안녕하세요, Hyun님! 어떻게 도와드릴까요?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 15, 'total_tokens': 29, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'id': 'chatcmpl-ByBuecd4biy6hmAGa6W5wcgCjrAnX', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--6f8fd5ca-0ddf-4f7e-a678-2406b3936bbf-0', usage_metadata={'input_tokens': 15, 'output_tokens': 14, 'total_tokens': 29, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), HumanMessage(content='제 이름이 뭐죠?', additional_kwargs={}, response_metadata={}, id='24a186bc-4285-4f90-a192-a3f22d844887'), AIMessage(content='당신의 이름은 Hyun입니다! 다른 질문이 있으신가요?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 43, 'total_tokens': 60, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'id': 'chatcmpl-ByBue5SxnCs163twPHgw7eoOcLEQX', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--d3831e28-db7f-4c03-a57c-a65649c2a917-0', usage_metadata={'input_tokens': 43, 'output_tokens': 17, 'total_tokens': 60, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), HumanMessage(content='전 LLM에 관심이 많습니다', additional_kwargs={}, response_metadata={}, id='272d9be2-0e9e-437e-9625-d2822593487d')]}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f06b7f1-00d8-6167-8005-0ffe0b547867'}}, metadata={'source': 'update', 'step': 5, 'parents': {}}, created_at='2025-07-28T06:49:52.282455+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f06b7e8-d9c5-6e23-8004-07ddda9f3671'}}, tasks=(), interrupts=())"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.get_state(thread1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65458cde",
   "metadata": {},
   "source": [
    "## 채팅 기록 수정 \n",
    "\n",
    "대부분의 경우, 채팅 기록 메세지는 모델이 정확한 응답을 생성하는 데 사용할 만큼 좋은 상태나 형식을 갖추지 못한다. 따라서 다음과 같은 방법으로 이를 해결한다. \n",
    "\n",
    "- **메세지 축약(trimming)**: LLM에서는 컨텍스트 윈도를 제한하는데, 이는 프롬프트로 입력 가능한 토큰 수에 한계가 존재한다는 의미이다. 실전에서는 최신 메시지만 로드하여 저장하는 정도로도 충분히 문제를 해결할 수 있다. `trim_messages` 메서드를 총해 채팅 기록에서 보존하겆나 삭제할 토큰 수를 지정할 수 있다.\n",
    "\n",
    "- **내용 필터링(filtering)**\n",
    "\n",
    "- **메시지 병합(merging)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "65bf74b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='당신은 친절한 어시스턴스입니다.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='1 + 2는 얼마죠?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='3입니다.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='고마워요', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import (\n",
    "    SystemMessage,\n",
    "    HumanMessage,\n",
    "    AIMessage,\n",
    "    trim_messages\n",
    ")\n",
    "\n",
    "# 간단한 메세지 설정 \n",
    "messages = [\n",
    "    SystemMessage(content = \"당신은 친절한 어시스턴스입니다.\"),\n",
    "    HumanMessage(content='안녕하세요. 저는 Hyun 입니다.'),\n",
    "    AIMessage(content='안녕하세요!'),\n",
    "    HumanMessage(content='엔지니어를 희망하고 있어요'),\n",
    "    AIMessage(content='어떤 분야의 엔지니어를 희망하고 있나요?'),\n",
    "    HumanMessage(content='AI나 분산처리 분야입니다.'),\n",
    "    AIMessage(content='좋네요!'),\n",
    "    HumanMessage(content='1 + 2는 얼마죠?'),\n",
    "    AIMessage(content='3입니다.'),\n",
    "    HumanMessage(content=\"고마워요\")\n",
    "]\n",
    "\n",
    "trimmer = trim_messages(\n",
    "    max_tokens = 65, \n",
    "    strategy = 'last', # 메세지 목록의 시작 지점 설정, 대체로 최신 메시지를 우선시하여 용량이 부족하면 오래된 메세지를 삭제하므로 last로 설정하여 가장 마지막 메세지를 시작 지점으로 설정 \n",
    "    token_counter = ChatOpenAI(model = 'gpt-4o-mini'), # 모델에 최적화된 토크나이저를 활용하여 토큰 산출 \n",
    "    include_system = True,\n",
    "    allow_partial = False, # False: 만약 마지막 메세지의 내용이 한도를 초과하면 메시지를 완전히 제거\n",
    "    start_on = 'human', # 응답인 AIMessage를 제거하면 그 응답을 불러온 질문인 HumanMessage도 함께 제거 \n",
    ")\n",
    "\n",
    "trimmed = trimmer.invoke(messages)\n",
    "trimmed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957bb013",
   "metadata": {},
   "source": [
    "### 메시지 필터링 \n",
    "\n",
    "- **`filter_messages()`**: 채팅 기록 메시지를 유형, Id, 이름별로 쉽게 구분 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d41fb685",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='안녕하세요. 저는 Hyun 입니다.', additional_kwargs={}, response_metadata={}, id='2'),\n",
       " HumanMessage(content='엔지니어를 희망하고 있어요', additional_kwargs={}, response_metadata={}, id='4'),\n",
       " HumanMessage(content='AI나 분산처리 분야입니다.', additional_kwargs={}, response_metadata={}, id='6'),\n",
       " HumanMessage(content='1 + 2는 얼마죠?', additional_kwargs={}, response_metadata={}, id='8'),\n",
       " HumanMessage(content='고마워요', additional_kwargs={}, response_metadata={}, id='10')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import filter_messages\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content = \"당신은 친절한 어시스턴스입니다.\", id = '1'),\n",
    "    HumanMessage(content='안녕하세요. 저는 Hyun 입니다.', id = '2'),\n",
    "    AIMessage(content='안녕하세요!', id = \"3\"),\n",
    "    HumanMessage(content='엔지니어를 희망하고 있어요', id = \"4\"),\n",
    "    AIMessage(content='어떤 분야의 엔지니어를 희망하고 있나요?', id = \"5\"),\n",
    "    HumanMessage(content='AI나 분산처리 분야입니다.', id = \"6\"),\n",
    "    AIMessage(content='좋네요!', id = \"7\"),\n",
    "    HumanMessage(content='1 + 2는 얼마죠?', id = \"8\"),\n",
    "    AIMessage(content='3입니다.', id = \"9\"),\n",
    "    HumanMessage(content=\"고마워요\", id = \"10\")\n",
    "]\n",
    "\n",
    "human_messages = filter_messages(messages, include_types = 'human')\n",
    "human_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2186865d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='안녕하세요. 저는 Hyun 입니다.', additional_kwargs={}, response_metadata={}, id='2'),\n",
       " HumanMessage(content='1 + 2는 얼마죠?', additional_kwargs={}, response_metadata={}, id='8'),\n",
       " HumanMessage(content='고마워요', additional_kwargs={}, response_metadata={}, id='10')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# id를 활용해서도 필터링 가능 \n",
    "filtered_messages = filter_messages(\n",
    "    messages, include_types = 'human', exclude_ids = ['4','6']\n",
    ")\n",
    "filtered_messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60589a59",
   "metadata": {},
   "source": [
    "### 연속된 메시지 병합\n",
    "\n",
    "일반적으로 일부 모델은 동일한 유형의 메시지를 연속으로 입력할 수 없는데, 랭체인의 `merge_message_runs()`를 이용하면 동일 유형의 연속된 메시지를 손쉽게 병합 가능하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0a9372b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='당신은 친절한 어시스턴스입니다.\\n항상 농답으로 대답하세요' additional_kwargs={} response_metadata={}\n",
      "content=[{'type': 'text', 'text': '어떤 피자가 제일 맛있나요?'}, '어떤 햄버거가 가장 맛있나요?'] additional_kwargs={} response_metadata={}\n",
      "content='나는 항상 너만 \"고르곤졸라\"\\n너가 \\'버거\\' 싶어' additional_kwargs={} response_metadata={}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import merge_message_runs\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content = \"당신은 친절한 어시스턴스입니다.\"),\n",
    "    SystemMessage(content = \"항상 농답으로 대답하세요\"),\n",
    "    HumanMessage(content = [{'type':'text', 'text': '어떤 피자가 제일 맛있나요?'}]),\n",
    "    HumanMessage(content = \"어떤 햄버거가 가장 맛있나요?\"),\n",
    "    AIMessage(content = '나는 항상 너만 \"고르곤졸라\"'),\n",
    "    AIMessage(content = \"너가 '버거' 싶어\"),\n",
    "]\n",
    "\n",
    "merged_messages = merge_message_runs(messages)\n",
    "\n",
    "for msg in merged_messages:\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c70ebd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ragenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
