{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c829f163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting chromaDB\n",
      "  Downloading chromadb-1.0.15-cp39-abi3-win_amd64.whl.metadata (7.1 kB)\n",
      "Collecting build>=1.0.3 (from chromaDB)\n",
      "  Downloading build-1.2.2.post1-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: pydantic>=1.9 in c:\\users\\user\\anaconda3\\envs\\ragenv\\lib\\site-packages (from chromaDB) (2.11.7)\n",
      "Collecting pybase64>=1.4.1 (from chromaDB)\n",
      "  Downloading pybase64-1.4.2-cp310-cp310-win_amd64.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in c:\\users\\user\\anaconda3\\envs\\ragenv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromaDB) (0.34.3)\n",
      "Requirement already satisfied: numpy>=1.22.5 in c:\\users\\user\\anaconda3\\envs\\ragenv\\lib\\site-packages (from chromaDB) (2.2.6)\n",
      "Collecting posthog<6.0.0,>=2.4.0 (from chromaDB)\n",
      "  Downloading posthog-5.4.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\user\\anaconda3\\envs\\ragenv\\lib\\site-packages (from chromaDB) (4.14.0)\n",
      "Collecting onnxruntime>=1.14.1 (from chromaDB)\n",
      "  Downloading onnxruntime-1.22.1-cp310-cp310-win_amd64.whl.metadata (5.1 kB)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromaDB)\n",
      "  Downloading opentelemetry_api-1.35.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromaDB)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.35.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromaDB)\n",
      "  Downloading opentelemetry_sdk-1.35.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting tokenizers>=0.13.2 (from chromaDB)\n",
      "  Using cached tokenizers-0.21.2-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting pypika>=0.48.9 (from chromaDB)\n",
      "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: tqdm>=4.65.0 in c:\\users\\user\\anaconda3\\envs\\ragenv\\lib\\site-packages (from chromaDB) (4.67.1)\n",
      "Collecting overrides>=7.3.1 (from chromaDB)\n",
      "  Using cached overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting importlib-resources (from chromaDB)\n",
      "  Using cached importlib_resources-6.5.2-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting grpcio>=1.58.0 (from chromaDB)\n",
      "  Downloading grpcio-1.74.0-cp310-cp310-win_amd64.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in c:\\users\\user\\anaconda3\\envs\\ragenv\\lib\\site-packages (from chromaDB) (4.3.0)\n",
      "Collecting typer>=0.9.0 (from chromaDB)\n",
      "  Using cached typer-0.16.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting kubernetes>=28.1.0 (from chromaDB)\n",
      "  Downloading kubernetes-33.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in c:\\users\\user\\anaconda3\\envs\\ragenv\\lib\\site-packages (from chromaDB) (9.1.2)\n",
      "Requirement already satisfied: pyyaml>=6.0.0 in c:\\users\\user\\anaconda3\\envs\\ragenv\\lib\\site-packages (from chromaDB) (6.0.2)\n",
      "Collecting mmh3>=4.0.1 (from chromaDB)\n",
      "  Downloading mmh3-5.1.0-cp310-cp310-win_amd64.whl.metadata (16 kB)\n",
      "Requirement already satisfied: orjson>=3.9.12 in c:\\users\\user\\anaconda3\\envs\\ragenv\\lib\\site-packages (from chromaDB) (3.11.0)\n",
      "Requirement already satisfied: httpx>=0.27.0 in c:\\users\\user\\anaconda3\\envs\\ragenv\\lib\\site-packages (from chromaDB) (0.28.1)\n",
      "Collecting rich>=10.11.0 (from chromaDB)\n",
      "  Downloading rich-14.1.0-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: jsonschema>=4.19.0 in c:\\users\\user\\anaconda3\\envs\\ragenv\\lib\\site-packages (from chromaDB) (4.25.0)\n",
      "Requirement already satisfied: requests<3.0,>=2.7 in c:\\users\\user\\anaconda3\\envs\\ragenv\\lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromaDB) (2.32.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\anaconda3\\envs\\ragenv\\lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromaDB) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.2 in c:\\users\\user\\anaconda3\\envs\\ragenv\\lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromaDB) (2.9.0.post0)\n",
      "Collecting backoff>=1.10.0 (from posthog<6.0.0,>=2.4.0->chromaDB)\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: distro>=1.5.0 in c:\\users\\user\\anaconda3\\envs\\ragenv\\lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromaDB) (1.9.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\user\\anaconda3\\envs\\ragenv\\lib\\site-packages (from requests<3.0,>=2.7->posthog<6.0.0,>=2.4.0->chromaDB) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\envs\\ragenv\\lib\\site-packages (from requests<3.0,>=2.7->posthog<6.0.0,>=2.4.0->chromaDB) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\anaconda3\\envs\\ragenv\\lib\\site-packages (from requests<3.0,>=2.7->posthog<6.0.0,>=2.4.0->chromaDB) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\envs\\ragenv\\lib\\site-packages (from requests<3.0,>=2.7->posthog<6.0.0,>=2.4.0->chromaDB) (2025.7.14)\n",
      "Requirement already satisfied: packaging>=19.1 in c:\\users\\user\\anaconda3\\envs\\ragenv\\lib\\site-packages (from build>=1.0.3->chromaDB) (25.0)\n",
      "Collecting pyproject_hooks (from build>=1.0.3->chromaDB)\n",
      "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\envs\\ragenv\\lib\\site-packages (from build>=1.0.3->chromaDB) (0.4.6)\n",
      "Collecting tomli>=1.1.0 (from build>=1.0.3->chromaDB)\n",
      "  Using cached tomli-2.2.1-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: anyio in c:\\users\\user\\anaconda3\\envs\\ragenv\\lib\\site-packages (from httpx>=0.27.0->chromaDB) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\user\\anaconda3\\envs\\ragenv\\lib\\site-packages (from httpx>=0.27.0->chromaDB) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\user\\anaconda3\\envs\\ragenv\\lib\\site-packages (from httpcore==1.*->httpx>=0.27.0->chromaDB) (0.16.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\user\\anaconda3\\envs\\ragenv\\lib\\site-packages (from jsonschema>=4.19.0->chromaDB) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\user\\anaconda3\\envs\\ragenv\\lib\\site-packages (from jsonschema>=4.19.0->chromaDB) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\user\\anaconda3\\envs\\ragenv\\lib\\site-packages (from jsonschema>=4.19.0->chromaDB) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\user\\anaconda3\\envs\\ragenv\\lib\\site-packages (from jsonschema>=4.19.0->chromaDB) (0.26.0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in c:\\users\\user\\anaconda3\\envs\\ragenv\\lib\\site-packages (from kubernetes>=28.1.0->chromaDB) (2.40.3)\n",
      "Collecting websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 (from kubernetes>=28.1.0->chromaDB)\n",
      "  Using cached websocket_client-1.8.0-py3-none-any.whl.metadata (8.0 kB)\n",
      "Collecting requests-oauthlib (from kubernetes>=28.1.0->chromaDB)\n",
      "  Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting oauthlib>=3.2.2 (from kubernetes>=28.1.0->chromaDB)\n",
      "  Downloading oauthlib-3.3.1-py3-none-any.whl.metadata (7.9 kB)\n",
      "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromaDB)\n",
      "  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\user\\anaconda3\\envs\\ragenv\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromaDB) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\user\\anaconda3\\envs\\ragenv\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromaDB) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\user\\anaconda3\\envs\\ragenv\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromaDB) (4.9.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\user\\anaconda3\\envs\\ragenv\\lib\\site-packages (from rsa<5,>=3.1.4->google-auth>=1.0.1->kubernetes>=28.1.0->chromaDB) (0.6.1)\n",
      "Collecting coloredlogs (from onnxruntime>=1.14.1->chromaDB)\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting flatbuffers (from onnxruntime>=1.14.1->chromaDB)\n",
      "  Using cached flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Requirement already satisfied: protobuf in c:\\users\\user\\anaconda3\\envs\\ragenv\\lib\\site-packages (from onnxruntime>=1.14.1->chromaDB) (6.31.1)\n",
      "Collecting sympy (from onnxruntime>=1.14.1->chromaDB)\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in c:\\users\\user\\anaconda3\\envs\\ragenv\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromaDB) (8.7.0)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\user\\anaconda3\\envs\\ragenv\\lib\\site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromaDB) (3.23.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.57 in c:\\users\\user\\anaconda3\\envs\\ragenv\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromaDB) (1.70.0)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.35.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromaDB)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.35.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting opentelemetry-proto==1.35.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromaDB)\n",
      "  Downloading opentelemetry_proto-1.35.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.56b0 (from opentelemetry-sdk>=1.2.0->chromaDB)\n",
      "  Downloading opentelemetry_semantic_conventions-0.56b0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\user\\anaconda3\\envs\\ragenv\\lib\\site-packages (from pydantic>=1.9->chromaDB) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\user\\anaconda3\\envs\\ragenv\\lib\\site-packages (from pydantic>=1.9->chromaDB) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\user\\anaconda3\\envs\\ragenv\\lib\\site-packages (from pydantic>=1.9->chromaDB) (0.4.1)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->chromaDB)\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\user\\anaconda3\\envs\\ragenv\\lib\\site-packages (from rich>=10.11.0->chromaDB) (2.19.2)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->chromaDB)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.16.4 (from tokenizers>=0.13.2->chromaDB)\n",
      "  Downloading huggingface_hub-0.34.1-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting filelock (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromaDB)\n",
      "  Using cached filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromaDB)\n",
      "  Using cached fsspec-2025.7.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\user\\anaconda3\\envs\\ragenv\\lib\\site-packages (from typer>=0.9.0->chromaDB) (8.2.1)\n",
      "Collecting shellingham>=1.3.0 (from typer>=0.9.0->chromaDB)\n",
      "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromaDB)\n",
      "  Downloading httptools-0.6.4-cp310-cp310-win_amd64.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in c:\\users\\user\\anaconda3\\envs\\ragenv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromaDB) (1.1.1)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromaDB)\n",
      "  Downloading watchfiles-1.1.0-cp310-cp310-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromaDB)\n",
      "  Downloading websockets-15.0.1-cp310-cp310-win_amd64.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\user\\anaconda3\\envs\\ragenv\\lib\\site-packages (from anyio->httpx>=0.27.0->chromaDB) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\user\\anaconda3\\envs\\ragenv\\lib\\site-packages (from anyio->httpx>=0.27.0->chromaDB) (1.3.1)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromaDB)\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting pyreadline3 (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromaDB)\n",
      "  Downloading pyreadline3-3.5.4-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy->onnxruntime>=1.14.1->chromaDB)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Downloading chromadb-1.0.15-cp39-abi3-win_amd64.whl (19.5 MB)\n",
      "   ---------------------------------------- 0.0/19.5 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 3.4/19.5 MB 15.5 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 6.3/19.5 MB 14.3 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 11.0/19.5 MB 17.6 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 16.0/19.5 MB 19.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 19.5/19.5 MB 19.6 MB/s eta 0:00:00\n",
      "Downloading posthog-5.4.0-py3-none-any.whl (105 kB)\n",
      "Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading build-1.2.2.post1-py3-none-any.whl (22 kB)\n",
      "Downloading grpcio-1.74.0-cp310-cp310-win_amd64.whl (4.5 MB)\n",
      "   ---------------------------------------- 0.0/4.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 4.5/4.5 MB 27.0 MB/s eta 0:00:00\n",
      "Downloading kubernetes-33.1.0-py2.py3-none-any.whl (1.9 MB)\n",
      "   ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.9/1.9 MB 26.7 MB/s eta 0:00:00\n",
      "Downloading durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
      "Downloading mmh3-5.1.0-cp310-cp310-win_amd64.whl (41 kB)\n",
      "Downloading oauthlib-3.3.1-py3-none-any.whl (160 kB)\n",
      "Downloading onnxruntime-1.22.1-cp310-cp310-win_amd64.whl (12.7 MB)\n",
      "   ---------------------------------------- 0.0/12.7 MB ? eta -:--:--\n",
      "   ------------------- -------------------- 6.0/12.7 MB 28.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 11.3/12.7 MB 26.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.7/12.7 MB 24.9 MB/s eta 0:00:00\n",
      "Downloading opentelemetry_api-1.35.0-py3-none-any.whl (65 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_grpc-1.35.0-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_common-1.35.0-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_proto-1.35.0-py3-none-any.whl (72 kB)\n",
      "Downloading opentelemetry_sdk-1.35.0-py3-none-any.whl (119 kB)\n",
      "Downloading opentelemetry_semantic_conventions-0.56b0-py3-none-any.whl (201 kB)\n",
      "Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
      "Downloading pybase64-1.4.2-cp310-cp310-win_amd64.whl (35 kB)\n",
      "Downloading rich-14.1.0-py3-none-any.whl (243 kB)\n",
      "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Using cached tokenizers-0.21.2-cp39-abi3-win_amd64.whl (2.5 MB)\n",
      "Downloading huggingface_hub-0.34.1-py3-none-any.whl (558 kB)\n",
      "   ---------------------------------------- 0.0/558.8 kB ? eta -:--:--\n",
      "   --------------------------------------- 558.8/558.8 kB 18.5 MB/s eta 0:00:00\n",
      "Using cached fsspec-2025.7.0-py3-none-any.whl (199 kB)\n",
      "Using cached tomli-2.2.1-py3-none-any.whl (14 kB)\n",
      "Using cached typer-0.16.0-py3-none-any.whl (46 kB)\n",
      "Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading httptools-0.6.4-cp310-cp310-win_amd64.whl (88 kB)\n",
      "Downloading watchfiles-1.1.0-cp310-cp310-win_amd64.whl (292 kB)\n",
      "Using cached websocket_client-1.8.0-py3-none-any.whl (58 kB)\n",
      "Downloading websockets-15.0.1-cp310-cp310-win_amd64.whl (176 kB)\n",
      "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Using cached filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Using cached flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Using cached importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
      "Downloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
      "Downloading pyreadline3-3.5.4-py3-none-any.whl (83 kB)\n",
      "Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Building wheels for collected packages: pypika\n",
      "  Building wheel for pypika (pyproject.toml): started\n",
      "  Building wheel for pypika (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53916 sha256=ae05db308bb7aefe14d379f601215e7a0d10cb0c27b9c5bb649033821735b206\n",
      "  Stored in directory: c:\\users\\user\\appdata\\local\\pip\\cache\\wheels\\e1\\26\\51\\d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n",
      "Successfully built pypika\n",
      "Installing collected packages: pypika, mpmath, flatbuffers, durationpy, websockets, websocket-client, tomli, sympy, shellingham, pyreadline3, pyproject_hooks, pybase64, overrides, opentelemetry-proto, oauthlib, mmh3, mdurl, importlib-resources, httptools, grpcio, fsspec, filelock, backoff, requests-oauthlib, posthog, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, markdown-it-py, humanfriendly, huggingface-hub, build, watchfiles, tokenizers, rich, opentelemetry-semantic-conventions, kubernetes, coloredlogs, typer, opentelemetry-sdk, onnxruntime, opentelemetry-exporter-otlp-proto-grpc, chromaDB\n",
      "\n",
      "    ---------------------------------------  1/42 [mpmath]\n",
      "    ---------------------------------------  1/42 [mpmath]\n",
      "    ---------------------------------------  1/42 [mpmath]\n",
      "   --- ------------------------------------  4/42 [websockets]\n",
      "   --- ------------------------------------  4/42 [websockets]\n",
      "   ----- ----------------------------------  6/42 [tomli]\n",
      "   ------ ---------------------------------  7/42 [sympy]\n",
      "   ------ ---------------------------------  7/42 [sympy]\n",
      "   ------ ---------------------------------  7/42 [sympy]\n",
      "   ------ ---------------------------------  7/42 [sympy]\n",
      "   ------ ---------------------------------  7/42 [sympy]\n",
      "   ------ ---------------------------------  7/42 [sympy]\n",
      "   ------ ---------------------------------  7/42 [sympy]\n",
      "   ------ ---------------------------------  7/42 [sympy]\n",
      "   ------ ---------------------------------  7/42 [sympy]\n",
      "   ------ ---------------------------------  7/42 [sympy]\n",
      "   ------ ---------------------------------  7/42 [sympy]\n",
      "   ------ ---------------------------------  7/42 [sympy]\n",
      "   ------ ---------------------------------  7/42 [sympy]\n",
      "   ------ ---------------------------------  7/42 [sympy]\n",
      "   ------ ---------------------------------  7/42 [sympy]\n",
      "   ------ ---------------------------------  7/42 [sympy]\n",
      "   ------ ---------------------------------  7/42 [sympy]\n",
      "   ------ ---------------------------------  7/42 [sympy]\n",
      "   ------ ---------------------------------  7/42 [sympy]\n",
      "   ------ ---------------------------------  7/42 [sympy]\n",
      "   ------ ---------------------------------  7/42 [sympy]\n",
      "   ------ ---------------------------------  7/42 [sympy]\n",
      "   ------ ---------------------------------  7/42 [sympy]\n",
      "   ------ ---------------------------------  7/42 [sympy]\n",
      "   ------ ---------------------------------  7/42 [sympy]\n",
      "   ------ ---------------------------------  7/42 [sympy]\n",
      "   ------ ---------------------------------  7/42 [sympy]\n",
      "   ------ ---------------------------------  7/42 [sympy]\n",
      "   ------ ---------------------------------  7/42 [sympy]\n",
      "   ------ ---------------------------------  7/42 [sympy]\n",
      "   ------ ---------------------------------  7/42 [sympy]\n",
      "   ------ ---------------------------------  7/42 [sympy]\n",
      "   ------ ---------------------------------  7/42 [sympy]\n",
      "   ------ ---------------------------------  7/42 [sympy]\n",
      "   ------ ---------------------------------  7/42 [sympy]\n",
      "   ------ ---------------------------------  7/42 [sympy]\n",
      "   ------ ---------------------------------  7/42 [sympy]\n",
      "   ------ ---------------------------------  7/42 [sympy]\n",
      "   ------ ---------------------------------  7/42 [sympy]\n",
      "   ------ ---------------------------------  7/42 [sympy]\n",
      "   ------ ---------------------------------  7/42 [sympy]\n",
      "   ------ ---------------------------------  7/42 [sympy]\n",
      "   ------ ---------------------------------  7/42 [sympy]\n",
      "   ------ ---------------------------------  7/42 [sympy]\n",
      "   ------ ---------------------------------  7/42 [sympy]\n",
      "   ------ ---------------------------------  7/42 [sympy]\n",
      "   ------ ---------------------------------  7/42 [sympy]\n",
      "   ------ ---------------------------------  7/42 [sympy]\n",
      "   ------ ---------------------------------  7/42 [sympy]\n",
      "   ------ ---------------------------------  7/42 [sympy]\n",
      "   ------ ---------------------------------  7/42 [sympy]\n",
      "   ------ ---------------------------------  7/42 [sympy]\n",
      "   ------ ---------------------------------  7/42 [sympy]\n",
      "   -------- -------------------------------  9/42 [pyreadline3]\n",
      "   -------- -------------------------------  9/42 [pyreadline3]\n",
      "   ----------- ---------------------------- 12/42 [overrides]\n",
      "   ------------ --------------------------- 13/42 [opentelemetry-proto]\n",
      "   ------------- -------------------------- 14/42 [oauthlib]\n",
      "   ------------- -------------------------- 14/42 [oauthlib]\n",
      "   --------------- ------------------------ 16/42 [mdurl]\n",
      "   ----------------- ---------------------- 18/42 [httptools]\n",
      "   ------------------ --------------------- 19/42 [grpcio]\n",
      "   ------------------- -------------------- 20/42 [fsspec]\n",
      "   ------------------- -------------------- 20/42 [fsspec]\n",
      "   --------------------- ------------------ 23/42 [requests-oauthlib]\n",
      "   ---------------------- ----------------- 24/42 [posthog]\n",
      "   ------------------------ --------------- 26/42 [opentelemetry-api]\n",
      "   ------------------------- -------------- 27/42 [markdown-it-py]\n",
      "   ------------------------- -------------- 27/42 [markdown-it-py]\n",
      "   --------------------------- ------------ 29/42 [huggingface-hub]\n",
      "   --------------------------- ------------ 29/42 [huggingface-hub]\n",
      "   --------------------------- ------------ 29/42 [huggingface-hub]\n",
      "   --------------------------- ------------ 29/42 [huggingface-hub]\n",
      "   ---------------------------- ----------- 30/42 [build]\n",
      "   ------------------------------ --------- 32/42 [tokenizers]\n",
      "   ------------------------------- -------- 33/42 [rich]\n",
      "   ------------------------------- -------- 33/42 [rich]\n",
      "   -------------------------- ------ 34/42 [opentelemetry-semantic-conventions]\n",
      "   -------------------------- ------ 34/42 [opentelemetry-semantic-conventions]\n",
      "   -------------------------- ------ 34/42 [opentelemetry-semantic-conventions]\n",
      "   --------------------------------- ------ 35/42 [kubernetes]\n",
      "   --------------------------------- ------ 35/42 [kubernetes]\n",
      "   --------------------------------- ------ 35/42 [kubernetes]\n",
      "   --------------------------------- ------ 35/42 [kubernetes]\n",
      "   --------------------------------- ------ 35/42 [kubernetes]\n",
      "   --------------------------------- ------ 35/42 [kubernetes]\n",
      "   --------------------------------- ------ 35/42 [kubernetes]\n",
      "   --------------------------------- ------ 35/42 [kubernetes]\n",
      "   --------------------------------- ------ 35/42 [kubernetes]\n",
      "   --------------------------------- ------ 35/42 [kubernetes]\n",
      "   --------------------------------- ------ 35/42 [kubernetes]\n",
      "   --------------------------------- ------ 35/42 [kubernetes]\n",
      "   --------------------------------- ------ 35/42 [kubernetes]\n",
      "   --------------------------------- ------ 35/42 [kubernetes]\n",
      "   --------------------------------- ------ 35/42 [kubernetes]\n",
      "   --------------------------------- ------ 35/42 [kubernetes]\n",
      "   --------------------------------- ------ 35/42 [kubernetes]\n",
      "   --------------------------------- ------ 35/42 [kubernetes]\n",
      "   --------------------------------- ------ 35/42 [kubernetes]\n",
      "   --------------------------------- ------ 35/42 [kubernetes]\n",
      "   ----------------------------------- ---- 37/42 [typer]\n",
      "   ------------------------------------ --- 38/42 [opentelemetry-sdk]\n",
      "   ------------------------------------- -- 39/42 [onnxruntime]\n",
      "   ------------------------------------- -- 39/42 [onnxruntime]\n",
      "   ------------------------------------- -- 39/42 [onnxruntime]\n",
      "   ------------------------------------- -- 39/42 [onnxruntime]\n",
      "   ------------------------------------- -- 39/42 [onnxruntime]\n",
      "   ------------------------------------- -- 39/42 [onnxruntime]\n",
      "   ------------------------------------- -- 39/42 [onnxruntime]\n",
      "   ------------------------------------- -- 39/42 [onnxruntime]\n",
      "   --------------------------- - 40/42 [opentelemetry-exporter-otlp-proto-grpc]\n",
      "   ---------------------------------------  41/42 [chromaDB]\n",
      "   ---------------------------------------  41/42 [chromaDB]\n",
      "   ---------------------------------------  41/42 [chromaDB]\n",
      "   ---------------------------------------  41/42 [chromaDB]\n",
      "   ---------------------------------------  41/42 [chromaDB]\n",
      "   ---------------------------------------  41/42 [chromaDB]\n",
      "   ---------------------------------------- 42/42 [chromaDB]\n",
      "\n",
      "Successfully installed backoff-2.2.1 build-1.2.2.post1 chromaDB-1.0.15 coloredlogs-15.0.1 durationpy-0.10 filelock-3.18.0 flatbuffers-25.2.10 fsspec-2025.7.0 grpcio-1.74.0 httptools-0.6.4 huggingface-hub-0.34.1 humanfriendly-10.0 importlib-resources-6.5.2 kubernetes-33.1.0 markdown-it-py-3.0.0 mdurl-0.1.2 mmh3-5.1.0 mpmath-1.3.0 oauthlib-3.3.1 onnxruntime-1.22.1 opentelemetry-api-1.35.0 opentelemetry-exporter-otlp-proto-common-1.35.0 opentelemetry-exporter-otlp-proto-grpc-1.35.0 opentelemetry-proto-1.35.0 opentelemetry-sdk-1.35.0 opentelemetry-semantic-conventions-0.56b0 overrides-7.7.0 posthog-5.4.0 pybase64-1.4.2 pypika-0.48.9 pyproject_hooks-1.2.0 pyreadline3-3.5.4 requests-oauthlib-2.0.0 rich-14.1.0 shellingham-1.5.4 sympy-1.14.0 tokenizers-0.21.2 tomli-2.2.1 typer-0.16.0 watchfiles-1.1.0 websocket-client-1.8.0 websockets-15.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install chromaDB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74ceb72",
   "metadata": {},
   "source": [
    "## AI에서의 RAG System\n",
    "\n",
    "- 인덱싱: 외부 데이터 소스를 전처리 한 후, 데이터를 나타내는 임베딩을 손쉽게 조회하도록 벡터 저장소에 저장\n",
    "- 검색: 질문을 바탕으로 벡터 저장소에 보관된 관련 임베딩 및 데이터 추출\n",
    "- 생성: 원래의 프롬프트와 RAG를 활용한 관련 문서를 종합하여 하나의 최종 프롬프트를 구성한 후, 이를 LLM에 전달 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86999eea",
   "metadata": {},
   "source": [
    "## 1. Indexing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "34c8657e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': './data/test.txt'}, page_content='인공지능(AI)은 21세기 가장 혁신적인 기술 중 하나로 손꼽히며, 우리의 삶과 사회 전반에 걸쳐 막대한 영향을 미치고 있습니다. AI의 역사는 1950년대 다트머스 회의에서 \"인공지능\"이라는 용어가 처음 사용되면서 시작되었습니다. 초기에는 주로 규칙 기반 시스템과 논리 추론에 중점을 두었으나, 계산 능력의 한계로 인해 \"AI 겨울\"이라는 침체기를 겪기도 했습니다. 그러나 2000년대 이후 딥러닝 기술의 발전과 빅데이터의 등장은 AI 연구에 새로운 활력을 불어넣었습니다. 특히 GPU와 같은 고성능 컴퓨팅 자원의 등장은 복잡한 신경망 모델을 훈련시키는 것을 가능하게 했습니다. 이러한 기술적 진보는 AI가 단순한 연구 단계를 넘어 실생활에 적용되는 시대를 열었습니다.\\n\\n현재 AI 기술은 머신러닝, 딥러닝, 자연어 처리(NLP), 컴퓨터 비전, 로보틱스 등 다양한 분야로 확장되었습니다. 머신러닝은 데이터를 기반으로 학습하여 패턴을 인식하고 예측하는 기술이며, 딥러닝은 여러 계층의 신경망을 통해 더욱 복잡한 특징을 학습하는 머신러닝의 한 분야입니다. 자연어 처리(NLP)는 컴퓨터가 인간의 언어를 이해하고 생성하며 번역하는 기술로, 챗봇, 음성 비서, 기계 번역 등에서 핵심적인 역할을 합니다. 컴퓨터 비전은 이미지를 분석하고 이해하여 객체 인식, 안면 인식, 자율 주행 등에 활용됩니다. 로보틱스는 AI를 로봇에 접목하여 자율적인 동작과 의사결정을 가능하게 합니다. 이러한 기술들은 서로 유기적으로 결합되어 더욱 강력한 AI 시스템을 구축하는 데 기여하고 있습니다. 특히, 강화 학습은 에이전트가 환경과 상호작용하며 보상을 통해 최적의 행동을 학습하는 방식으로, 게임 플레이나 로봇 제어 등에서 뛰어난 성과를 보여주고 있습니다.\\n\\nAI의 발전은 의료, 금융, 교육, 제조, 유통 등 거의 모든 산업 분야에 혁신을 가져오고 있습니다. 의료 분야에서는 질병 진단 보조, 신약 개발, 맞춤형 치료법 제안 등에 AI가 활용되어 의료 서비스의 질을 높이고 있습니다. 금융 분야에서는 사기 탐지, 주식 시장 예측, 신용 평가 등에 AI가 적용되어 효율성과 보안을 강화하고 있습니다. 교육 분야에서는 개인 맞춤형 학습 콘텐츠 제공, 학생들의 학습 패턴 분석 등에 AI가 사용되어 교육의 효과를 극대화하고 있습니다. 제조 분야에서는 생산 공정 최적화, 불량품 검출, 로봇 자동화 등에 AI가 활용되어 생산성을 향상시키고 있습니다. 유통 분야에서는 고객 행동 분석, 재고 관리, 물류 최적화 등에 AI가 적용되어 고객 만족도를 높이고 비용을 절감하고 있습니다. 이러한 산업별 적용 사례들은 AI가 더 이상 먼 미래의 기술이 아닌, 현재 우리의 삶 속에서 실질적인 가치를 창출하고 있음을 보여줍니다.\\n\\n미래의 AI는 더욱 인간과 유사한 상호작용이 가능한 방향으로 발전할 것으로 예상됩니다. 제너레이티브 AI(생성형 AI)는 텍스트, 이미지, 오디오 등 다양한 형태의 콘텐츠를 스스로 생성하는 능력을 보여주며, 이는 창의적인 산업과 개인의 생산성을 혁신할 잠재력을 가지고 있습니다. 이와 함께 멀티모달 AI는 텍스트, 이미지, 음성 등 여러 형태의 데이터를 동시에 이해하고 처리하여 더욱 풍부한 상호작용을 가능하게 할 것입니다. 또한, 설명 가능한 AI(XAI)에 대한 연구가 활발히 진행되어 AI의 의사결정 과정을 투명하게 이해하고 신뢰성을 높이는 데 기여할 것입니다. AI 윤리와 안전성 또한 중요한 화두로 떠오르고 있으며, AI가 사회에 미치는 긍정적 영향을 극대화하고 부정적 영향을 최소화하기 위한 노력이 계속될 것입니다. 궁극적으로 AI는 인간의 지능을 보완하고 확장하여 인류의 삶의 질을 향상시키는 데 기여할 것입니다. 우리는 AI와 공존하며 새로운 시대를 열어갈 준비를 해야 합니다.\\n\\nAI의 급속한 발전은 사회 전반에 걸쳐 다양한 윤리적, 사회적 질문을 던지고 있습니다. 가장 큰 우려 중 하나는 일자리 변화입니다. AI와 자동화 기술은 반복적이고 예측 가능한 업무를 대체하며, 일부 직업의 소멸을 가속화할 수 있습니다. 그러나 동시에 새로운 유형의 직업을 창출하고, 인간이 더욱 창의적이고 전략적인 업무에 집중할 수 있도록 도울 것이라는 긍정적인 전망도 있습니다. 중요한 것은 이러한 변화에 대비하여 교육 시스템을 개편하고, 평생 학습의 기회를 제공하며, 사회 안전망을 강화하는 것입니다. 또한, AI 기술의 혜택이 특정 계층에만 집중되지 않도록 공정한 접근성을 보장하는 것도 중요합니다. 디지털 격차 심화는 사회적 불평등을 더욱 악화시킬 수 있기 때문입니다.\\n\\n또 다른 중요한 논의는 AI의 책임성 문제입니다. 자율주행차의 사고, AI 기반 의료 진단의 오류 등 AI 시스템의 오작동으로 인한 피해 발생 시 누구에게 책임이 있는가에 대한 법적, 윤리적 프레임워크가 필요합니다. 이는 AI 개발자, 배포자, 사용자 등 다양한 주체 간의 책임 분배를 명확히 하는 복잡한 문제입니다. 개인 정보 보호 또한 AI 시대의 핵심 과제입니다. AI 모델은 방대한 데이터를 학습하며, 이 과정에서 민감한 개인 정보가 유출되거나 오용될 위험이 있습니다. 데이터 수집, 저장, 활용에 대한 명확한 규제와 사용자 동의 절차, 그리고 강력한 보안 기술의 적용이 필수적입니다. 데이터 편향성으로 인한 차별 문제도 심각합니다. 학습 데이터에 특정 집단에 대한 편향이 존재할 경우, AI 시스템은 불공정하거나 차별적인 결과를 내놓을 수 있습니다. 이는 AI의 설계 단계부터 다양한 데이터를 포함하고, 편향성을 감지하고 완화하는 기술을 개발함으로써 해결해야 합니다.\\n\\nAI의 군사적 활용 역시 국제사회의 주요 관심사입니다. 자율 살상 무기(LAWS)의 개발과 배치는 인류의 통제력을 벗어난 심각한 위협이 될 수 있다는 우려가 제기되고 있습니다. 이에 대한 국제적인 합의와 규제 마련이 시급하며, AI의 평화적 사용을 위한 노력이 병행되어야 합니다. AI가 인간의 인지 능력을 뛰어넘는 특이점(Singularity)에 도달할 것이라는 논의도 있지만, 이는 아직 먼 미래의 가설로 여겨집니다. 중요한 것은 현재 우리가 마주한 AI 기술의 실제적인 영향과 잠재적 위험을 이해하고, 이를 통제하고 관리할 수 있는 능력을 키우는 것입니다. AI는 단순히 도구가 아니라, 사회 구조와 인간의 삶의 방식 자체를 변화시키는 강력한 힘을 가지고 있기 때문입니다.\\n\\n결론적으로, AI는 인류에게 전례 없는 기회를 제공하는 동시에, 신중한 접근과 지속적인 논의를 요구하는 복잡한 기술입니다. 기술 발전의 속도에 발맞춰 사회적, 윤리적, 법적 프레임워크를 마련하고, 투명하고 책임감 있는 AI 개발과 활용을 위한 국제적인 협력이 필수적입니다. 우리는 AI의 잠재력을 최대한 활용하면서도, 그로 인한 위험을 최소화하고 모든 인류에게 혜택이 돌아갈 수 있도록 지혜를 모아야 할 것입니다. AI 교육의 확산과 대중의 이해 증진도 이러한 과정에서 중요한 역할을 합니다. 지속적인 연구와 사회적 합의를 통해 AI가 인류의 번영에 기여하는 길을 모색해야 합니다.')]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.runnables import chain\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv(\"../../.env\")\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# 문서 로드\n",
    "raw_document = TextLoader(\"./data/test.txt\", encoding='utf-8').load()\n",
    "raw_document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "968fab7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': './data/test.txt'}, page_content='인공지능(AI)은 21세기 가장 혁신적인 기술 중 하나로 손꼽히며, 우리의 삶과 사회 전반에 걸쳐 막대한 영향을 미치고 있습니다. AI의 역사는 1950년대 다트머스 회의에서 \"인공지능\"이라는 용어가 처음 사용되면서 시작되었습니다. 초기에는 주로 규칙 기반 시스템과 논리 추론에 중점을 두었으나, 계산 능력의 한계로 인해 \"AI 겨울\"이라는 침체기를 겪기도 했습니다. 그러나 2000년대 이후 딥러닝 기술의 발전과 빅데이터의 등장은 AI 연구에 새로운 활력을 불어넣었습니다. 특히 GPU와 같은 고성능 컴퓨팅 자원의 등장은 복잡한 신경망 모델을 훈련시키는 것을 가능하게 했습니다. 이러한 기술적 진보는 AI가 단순한 연구 단계를 넘어 실생활에 적용되는 시대를 열었습니다.'),\n",
       " Document(metadata={'source': './data/test.txt'}, page_content='현재 AI 기술은 머신러닝, 딥러닝, 자연어 처리(NLP), 컴퓨터 비전, 로보틱스 등 다양한 분야로 확장되었습니다. 머신러닝은 데이터를 기반으로 학습하여 패턴을 인식하고 예측하는 기술이며, 딥러닝은 여러 계층의 신경망을 통해 더욱 복잡한 특징을 학습하는 머신러닝의 한 분야입니다. 자연어 처리(NLP)는 컴퓨터가 인간의 언어를 이해하고 생성하며 번역하는 기술로, 챗봇, 음성 비서, 기계 번역 등에서 핵심적인 역할을 합니다. 컴퓨터 비전은 이미지를 분석하고 이해하여 객체 인식, 안면 인식, 자율 주행 등에 활용됩니다. 로보틱스는 AI를 로봇에 접목하여 자율적인 동작과 의사결정을 가능하게 합니다. 이러한 기술들은 서로 유기적으로 결합되어 더욱 강력한 AI 시스템을 구축하는 데 기여하고 있습니다. 특히, 강화 학습은 에이전트가 환경과 상호작용하며 보상을 통해 최적의 행동을 학습하는 방식으로, 게임 플레이나 로봇 제어 등에서 뛰어난 성과를 보여주고 있습니다.'),\n",
       " Document(metadata={'source': './data/test.txt'}, page_content='AI의 발전은 의료, 금융, 교육, 제조, 유통 등 거의 모든 산업 분야에 혁신을 가져오고 있습니다. 의료 분야에서는 질병 진단 보조, 신약 개발, 맞춤형 치료법 제안 등에 AI가 활용되어 의료 서비스의 질을 높이고 있습니다. 금융 분야에서는 사기 탐지, 주식 시장 예측, 신용 평가 등에 AI가 적용되어 효율성과 보안을 강화하고 있습니다. 교육 분야에서는 개인 맞춤형 학습 콘텐츠 제공, 학생들의 학습 패턴 분석 등에 AI가 사용되어 교육의 효과를 극대화하고 있습니다. 제조 분야에서는 생산 공정 최적화, 불량품 검출, 로봇 자동화 등에 AI가 활용되어 생산성을 향상시키고 있습니다. 유통 분야에서는 고객 행동 분석, 재고 관리, 물류 최적화 등에 AI가 적용되어 고객 만족도를 높이고 비용을 절감하고 있습니다. 이러한 산업별 적용 사례들은 AI가 더 이상 먼 미래의 기술이 아닌, 현재 우리의 삶 속에서 실질적인 가치를 창출하고 있음을 보여줍니다.'),\n",
       " Document(metadata={'source': './data/test.txt'}, page_content='미래의 AI는 더욱 인간과 유사한 상호작용이 가능한 방향으로 발전할 것으로 예상됩니다. 제너레이티브 AI(생성형 AI)는 텍스트, 이미지, 오디오 등 다양한 형태의 콘텐츠를 스스로 생성하는 능력을 보여주며, 이는 창의적인 산업과 개인의 생산성을 혁신할 잠재력을 가지고 있습니다. 이와 함께 멀티모달 AI는 텍스트, 이미지, 음성 등 여러 형태의 데이터를 동시에 이해하고 처리하여 더욱 풍부한 상호작용을 가능하게 할 것입니다. 또한, 설명 가능한 AI(XAI)에 대한 연구가 활발히 진행되어 AI의 의사결정 과정을 투명하게 이해하고 신뢰성을 높이는 데 기여할 것입니다. AI 윤리와 안전성 또한 중요한 화두로 떠오르고 있으며, AI가 사회에 미치는 긍정적 영향을 극대화하고 부정적 영향을 최소화하기 위한 노력이 계속될 것입니다. 궁극적으로 AI는 인간의 지능을 보완하고 확장하여 인류의 삶의 질을 향상시키는 데 기여할 것입니다. 우리는 AI와 공존하며 새로운 시대를 열어갈 준비를 해야 합니다.'),\n",
       " Document(metadata={'source': './data/test.txt'}, page_content='AI의 급속한 발전은 사회 전반에 걸쳐 다양한 윤리적, 사회적 질문을 던지고 있습니다. 가장 큰 우려 중 하나는 일자리 변화입니다. AI와 자동화 기술은 반복적이고 예측 가능한 업무를 대체하며, 일부 직업의 소멸을 가속화할 수 있습니다. 그러나 동시에 새로운 유형의 직업을 창출하고, 인간이 더욱 창의적이고 전략적인 업무에 집중할 수 있도록 도울 것이라는 긍정적인 전망도 있습니다. 중요한 것은 이러한 변화에 대비하여 교육 시스템을 개편하고, 평생 학습의 기회를 제공하며, 사회 안전망을 강화하는 것입니다. 또한, AI 기술의 혜택이 특정 계층에만 집중되지 않도록 공정한 접근성을 보장하는 것도 중요합니다. 디지털 격차 심화는 사회적 불평등을 더욱 악화시킬 수 있기 때문입니다.'),\n",
       " Document(metadata={'source': './data/test.txt'}, page_content='또 다른 중요한 논의는 AI의 책임성 문제입니다. 자율주행차의 사고, AI 기반 의료 진단의 오류 등 AI 시스템의 오작동으로 인한 피해 발생 시 누구에게 책임이 있는가에 대한 법적, 윤리적 프레임워크가 필요합니다. 이는 AI 개발자, 배포자, 사용자 등 다양한 주체 간의 책임 분배를 명확히 하는 복잡한 문제입니다. 개인 정보 보호 또한 AI 시대의 핵심 과제입니다. AI 모델은 방대한 데이터를 학습하며, 이 과정에서 민감한 개인 정보가 유출되거나 오용될 위험이 있습니다. 데이터 수집, 저장, 활용에 대한 명확한 규제와 사용자 동의 절차, 그리고 강력한 보안 기술의 적용이 필수적입니다. 데이터 편향성으로 인한 차별 문제도 심각합니다. 학습 데이터에 특정 집단에 대한 편향이 존재할 경우, AI 시스템은 불공정하거나 차별적인 결과를 내놓을 수 있습니다. 이는 AI의 설계 단계부터 다양한 데이터를 포함하고, 편향성을 감지하고 완화하는 기술을 개발함으로써 해결해야 합니다.'),\n",
       " Document(metadata={'source': './data/test.txt'}, page_content='AI의 군사적 활용 역시 국제사회의 주요 관심사입니다. 자율 살상 무기(LAWS)의 개발과 배치는 인류의 통제력을 벗어난 심각한 위협이 될 수 있다는 우려가 제기되고 있습니다. 이에 대한 국제적인 합의와 규제 마련이 시급하며, AI의 평화적 사용을 위한 노력이 병행되어야 합니다. AI가 인간의 인지 능력을 뛰어넘는 특이점(Singularity)에 도달할 것이라는 논의도 있지만, 이는 아직 먼 미래의 가설로 여겨집니다. 중요한 것은 현재 우리가 마주한 AI 기술의 실제적인 영향과 잠재적 위험을 이해하고, 이를 통제하고 관리할 수 있는 능력을 키우는 것입니다. AI는 단순히 도구가 아니라, 사회 구조와 인간의 삶의 방식 자체를 변화시키는 강력한 힘을 가지고 있기 때문입니다.'),\n",
       " Document(metadata={'source': './data/test.txt'}, page_content='결론적으로, AI는 인류에게 전례 없는 기회를 제공하는 동시에, 신중한 접근과 지속적인 논의를 요구하는 복잡한 기술입니다. 기술 발전의 속도에 발맞춰 사회적, 윤리적, 법적 프레임워크를 마련하고, 투명하고 책임감 있는 AI 개발과 활용을 위한 국제적인 협력이 필수적입니다. 우리는 AI의 잠재력을 최대한 활용하면서도, 그로 인한 위험을 최소화하고 모든 인류에게 혜택이 돌아갈 수 있도록 지혜를 모아야 할 것입니다. AI 교육의 확산과 대중의 이해 증진도 이러한 과정에서 중요한 역할을 합니다. 지속적인 연구와 사회적 합의를 통해 AI가 인류의 번영에 기여하는 길을 모색해야 합니다.')]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "  chunk_size = 500, chunk_overlap = 200\n",
    ")\n",
    "\n",
    "documents = text_splitter.split_documents(raw_document)\n",
    "documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586298e4",
   "metadata": {},
   "source": [
    "### ChromaDB 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "058981d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = OpenAIEmbeddings(api_key=api_key)\n",
    "\n",
    "persist_directory = \"./chroma_db_data\" # ChromaDB가 데이터를 저장할 로컬 파일 시스템의 경로를 지정 \n",
    "\n",
    "db = Chroma.from_documents(\n",
    "  documents, \n",
    "  embedding_model,\n",
    "  persist_directory=persist_directory\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f530ff",
   "metadata": {},
   "source": [
    "### SQLite3로 ChromaDB 탐색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "151ef3a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테이블 목록\n",
      "migrations\n",
      "acquire_write\n",
      "collection_metadata\n",
      "segment_metadata\n",
      "tenants\n",
      "databases\n",
      "collections\n",
      "maintenance_log\n",
      "segments\n",
      "embeddings\n",
      "embedding_metadata\n",
      "max_seq_id\n",
      "embedding_fulltext_search\n",
      "embedding_fulltext_search_data\n",
      "embedding_fulltext_search_idx\n",
      "embedding_fulltext_search_content\n",
      "embedding_fulltext_search_docsize\n",
      "embedding_fulltext_search_config\n",
      "embeddings_queue\n",
      "embeddings_queue_config\n",
      "\n",
      "--- 'embeddings' 테이블 내용 (처음 3개 행) ---\n",
      "(1, '00094581-86e2-4dbe-acf9-c7520ff30d45', '15ece929-9c41-4391-946d-2a8efd257b57', 1, '2025-07-28 00:41:01')\n",
      "------------------------------\n",
      "(2, '00094581-86e2-4dbe-acf9-c7520ff30d45', '76a06d57-824f-4060-b68a-8634f905bf08', 2, '2025-07-28 00:41:01')\n",
      "------------------------------\n",
      "(3, '00094581-86e2-4dbe-acf9-c7520ff30d45', '636992f3-0767-46c0-94d1-0c31fc91962e', 3, '2025-07-28 01:19:37')\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import json\n",
    "\n",
    "# chroma.sqlite3 경로 \n",
    "data_path = \"./chroma_db_data/chroma.sqlite3\"\n",
    "\n",
    "try:\n",
    "  conn = sqlite3.connect(data_path)\n",
    "  cursor = conn.cursor() # db 실행\n",
    "  \n",
    "  print(f\"테이블 목록\")\n",
    "  # sqlite_master 테이블에서 type이 table인 것의 name 선택 \n",
    "  cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "  tables = cursor.fetchall()\n",
    "  # table 컬럼 확인 \n",
    "  for table in tables:\n",
    "        print(table[0])\n",
    "  print(\"\\n--- 'embeddings' 테이블 내용 (처음 3개 행) ---\")\n",
    "    # 보통 .tables 명령어로 정확한 테이블명을 확인 후 사용\n",
    "    \n",
    "  cursor.execute(\"SELECT * FROM embeddings LIMIT 3;\")\n",
    "  rows = cursor.fetchall()\n",
    "\n",
    "  for row in rows:\n",
    "      #embedding_str = row\n",
    "      print(row)\n",
    "    \n",
    "      #print(f\"Embedding (first 20 chars): {embedding_str[:20]}...\")\n",
    "      print(\"-\" * 30)\n",
    "\n",
    "except sqlite3.Error as e:\n",
    "  print(f\"데이터베이스 연결 또는 쿼리 오류: {e}\")\n",
    "finally:\n",
    "  if 'conn' in locals() and conn:\n",
    "      conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b4a415",
   "metadata": {},
   "source": [
    "## 2. Retriever\n",
    "- 입력된 질의를 임베딩 형태로 변환\n",
    "- 벡터 저장소에서 사용자 질의와 가장 유사한 임베딩 산출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "22817d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': './data/test.txt'}, page_content='현재 AI 기술은 머신러닝, 딥러닝, 자연어 처리(NLP), 컴퓨터 비전, 로보틱스 등 다양한 분야로 확장되었습니다. 머신러닝은 데이터를 기반으로 학습하여 패턴을 인식하고 예측하는 기술이며, 딥러닝은 여러 계층의 신경망을 통해 더욱 복잡한 특징을 학습하는 머신러닝의 한 분야입니다. 자연어 처리(NLP)는 컴퓨터가 인간의 언어를 이해하고 생성하며 번역하는 기술로, 챗봇, 음성 비서, 기계 번역 등에서 핵심적인 역할을 합니다. 컴퓨터 비전은 이미지를 분석하고 이해하여 객체 인식, 안면 인식, 자율 주행 등에 활용됩니다. 로보틱스는 AI를 로봇에 접목하여 자율적인 동작과 의사결정을 가능하게 합니다. 이러한 기술들은 서로 유기적으로 결합되어 더욱 강력한 AI 시스템을 구축하는 데 기여하고 있습니다. 특히, 강화 학습은 에이전트가 환경과 상호작용하며 보상을 통해 최적의 행동을 학습하는 방식으로, 게임 플레이나 로봇 제어 등에서 뛰어난 성과를 보여주고 있습니다.'), Document(metadata={'source': './data/test.txt'}, page_content='인공지능(AI)은 21세기 가장 혁신적인 기술 중 하나로 손꼽히며, 우리의 삶과 사회 전반에 걸쳐 막대한 영향을 미치고 있습니다. AI의 역사는 1950년대 다트머스 회의에서 \"인공지능\"이라는 용어가 처음 사용되면서 시작되었습니다. 초기에는 주로 규칙 기반 시스템과 논리 추론에 중점을 두었으나, 계산 능력의 한계로 인해 \"AI 겨울\"이라는 침체기를 겪기도 했습니다. 그러나 2000년대 이후 딥러닝 기술의 발전과 빅데이터의 등장은 AI 연구에 새로운 활력을 불어넣었습니다. 특히 GPU와 같은 고성능 컴퓨팅 자원의 등장은 복잡한 신경망 모델을 훈련시키는 것을 가능하게 했습니다.\\n\\n현재 AI 기술은 머신러닝, 딥러닝, 자연어 처리(NLP), 컴퓨터 비전, 로보틱스 등 다양한 분야로 확장되었습니다. 머신러닝은 데이터를 기반으로 학습하여 패턴을 인식하고 예측하는 기술이며, 딥러닝은 여러 계층의 신경망을 통해 더욱 복잡한 특징을 학습하는 머신러닝의 한 분야입니다. 자연어 처리(NLP)는 컴퓨터가 인간의 언어를 이해하고 생성하며 번역하는 기술로, 챗봇, 음성 비서, 기계 번역 등에서 핵심적인 역할을 합니다. 컴퓨터 비전은 이미지를 분석하고 이해하여 객체 인식, 안면 인식, 자율 주행 등에 활용됩니다. 로보틱스는 AI를 로봇에 접목하여 자율적인 동작과 의사결정을 가능하게 합니다. 이러한 기술들은 서로 유기적으로 결합되어 더욱 강력한 AI 시스템을 구축하는 데 기여하고 있습니다.'), Document(metadata={'source': './data/test.txt'}, page_content='인공지능(AI)은 21세기 가장 혁신적인 기술 중 하나로 손꼽히며, 우리의 삶과 사회 전반에 걸쳐 막대한 영향을 미치고 있습니다. AI의 역사는 1950년대 다트머스 회의에서 \"인공지능\"이라는 용어가 처음 사용되면서 시작되었습니다. 초기에는 주로 규칙 기반 시스템과 논리 추론에 중점을 두었으나, 계산 능력의 한계로 인해 \"AI 겨울\"이라는 침체기를 겪기도 했습니다. 그러나 2000년대 이후 딥러닝 기술의 발전과 빅데이터의 등장은 AI 연구에 새로운 활력을 불어넣었습니다. 특히 GPU와 같은 고성능 컴퓨팅 자원의 등장은 복잡한 신경망 모델을 훈련시키는 것을 가능하게 했습니다. 이러한 기술적 진보는 AI가 단순한 연구 단계를 넘어 실생활에 적용되는 시대를 열었습니다.'), Document(metadata={'source': './data/test.txt'}, page_content='미래의 AI는 더욱 인간과 유사한 상호작용이 가능한 방향으로 발전할 것으로 예상됩니다. 제너레이티브 AI(생성형 AI)는 텍스트, 이미지, 오디오 등 다양한 형태의 콘텐츠를 스스로 생성하는 능력을 보여주며, 이는 창의적인 산업과 개인의 생산성을 혁신할 잠재력을 가지고 있습니다. 이와 함께 멀티모달 AI는 텍스트, 이미지, 음성 등 여러 형태의 데이터를 동시에 이해하고 처리하여 더욱 풍부한 상호작용을 가능하게 할 것입니다. 또한, 설명 가능한 AI(XAI)에 대한 연구가 활발히 진행되어 AI의 의사결정 과정을 투명하게 이해하고 신뢰성을 높이는 데 기여할 것입니다. AI 윤리와 안전성 또한 중요한 화두로 떠오르고 있으며, AI가 사회에 미치는 긍정적 영향을 극대화하고 부정적 영향을 최소화하기 위한 노력이 계속될 것입니다. 궁극적으로 AI는 인간의 지능을 보완하고 확장하여 인류의 삶의 질을 향상시키는 데 기여할 것입니다. 우리는 AI와 공존하며 새로운 시대를 열어갈 준비를 해야 합니다.')]\n"
     ]
    }
   ],
   "source": [
    "# 질의 임베딩 및 벡터 저장소를 통해 실행하는 유사도 검색 계산 로직 추상화 \n",
    "retriever = db.as_retriever() \n",
    "\n",
    "query = \"컴퓨터 비전 기술은 무엇인가요?\"\n",
    "\n",
    "# 관련 문서를 받아옴 \n",
    "print(retriever.invoke(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8c618fc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': './data/test.txt'}, page_content='인공지능(AI)은 21세기 가장 혁신적인 기술 중 하나로 손꼽히며, 우리의 삶과 사회 전반에 걸쳐 막대한 영향을 미치고 있습니다. AI의 역사는 1950년대 다트머스 회의에서 \"인공지능\"이라는 용어가 처음 사용되면서 시작되었습니다. 초기에는 주로 규칙 기반 시스템과 논리 추론에 중점을 두었으나, 계산 능력의 한계로 인해 \"AI 겨울\"이라는 침체기를 겪기도 했습니다. 그러나 2000년대 이후 딥러닝 기술의 발전과 빅데이터의 등장은 AI 연구에 새로운 활력을 불어넣었습니다. 특히 GPU와 같은 고성능 컴퓨팅 자원의 등장은 복잡한 신경망 모델을 훈련시키는 것을 가능하게 했습니다. 이러한 기술적 진보는 AI가 단순한 연구 단계를 넘어 실생활에 적용되는 시대를 열었습니다.'),\n",
       " Document(metadata={'source': './data/test.txt'}, page_content='AI의 군사적 활용 역시 국제사회의 주요 관심사입니다. 자율 살상 무기(LAWS)의 개발과 배치는 인류의 통제력을 벗어난 심각한 위협이 될 수 있다는 우려가 제기되고 있습니다. 이에 대한 국제적인 합의와 규제 마련이 시급하며, AI의 평화적 사용을 위한 노력이 병행되어야 합니다. AI가 인간의 인지 능력을 뛰어넘는 특이점(Singularity)에 도달할 것이라는 논의도 있지만, 이는 아직 먼 미래의 가설로 여겨집니다. 중요한 것은 현재 우리가 마주한 AI 기술의 실제적인 영향과 잠재적 위험을 이해하고, 이를 통제하고 관리할 수 있는 능력을 키우는 것입니다. AI는 단순히 도구가 아니라, 사회 구조와 인간의 삶의 방식 자체를 변화시키는 강력한 힘을 가지고 있기 때문입니다.')]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = db.as_retriever(search_kwargs = {\"k\" : 2})\n",
    "query = \"군사 차원에서 인공지능에 대해 알려줘?\"\n",
    "\n",
    "docs = retriever.invoke(query)\n",
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16bc4a06",
   "metadata": {},
   "source": [
    "## 3. Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3bee3718",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=' 다음 컨텍스트만 사용하여 질문에 응답하시오.\\n컨텍스트: {context}\\n\\n질문: {question}\\n'), additional_kwargs={})])\n",
       "| ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x0000027BB442D090>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x0000027BB442EAA0>, root_client=<openai.OpenAI object at 0x0000027BB442EC50>, root_async_client=<openai.AsyncOpenAI object at 0x0000027BB442F7F0>, model_name='gpt-4o-mini', temperature=0.7, model_kwargs={}, openai_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retriever = db.as_retriever(search_kwargs = {\"k\" : 3})\n",
    "# from_template는 심플한 문자열이 채워진 단일 객체 리스트 \n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "''' 다음 컨텍스트만 사용하여 질문에 응답하시오.\n",
    "컨텍스트: {context}\n",
    "\n",
    "질문: {question}\n",
    "'''\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "  model = \"gpt-4o-mini\",\n",
    "  api_key=api_key,\n",
    "  temperature = 0.7,\n",
    ")\n",
    "\n",
    "llm_chain = prompt | llm \n",
    "llm_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "437913cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'군사 차원에서 인공지능(AI)의 활용은 국제 사회에서 주요 관심사로 떠오르고 있습니다. 특히 자율 살상 무기(LAWS)의 개발과 배치는 인류의 통제력을 벗어난 심각한 위협이 될 수 있다는 우려가 제기되고 있습니다. 이러한 문제를 해결하기 위해 국제적인 합의와 규제 마련이 시급하며, 동시에 AI의 평화적 사용을 위한 노력도 필요합니다. AI가 인간의 인지 능력을 뛰어넘는 특이점(Singularity)에 도달할 가능성에 대한 논의도 있지만, 이는 아직 먼 미래의 가설로 여겨지고 있습니다. 따라서 현재 우리가 마주한 AI 기술의 실제적인 영향과 잠재적 위험을 이해하고, 이를 통제하고 관리할 수 있는 능력을 키우는 것이 중요합니다. AI는 단순한 도구가 아니라 사회 구조와 인간의 삶의 방식을 변화시키는 강력한 힘을 가지고 있기 때문입니다.'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = llm_chain.invoke({'context':docs, \"question\": query})\n",
    "result.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e462d521",
   "metadata": {},
   "source": [
    "### Retriever 로직 캡슐화\n",
    "- `@chain`: 파이썬 데코레이터를 통해 함수를 러너블 체인으로 전환하여 `invoke()`나 `batch()` 메서드를 사용할 수 있게 만드는 것. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "76353414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'군사 차원에서 인공지능(AI)의 활용은 국제사회의 주요 관심사 중 하나입니다. 특히 자율 살상 무기(LAWS)의 개발과 배치는 인류의 통제력을 벗어난 심각한 위협이 될 수 있다는 우려가 제기되고 있습니다. 이러한 상황에서는 국제적인 합의와 규제 마련이 시급하며, AI의 평화적 사용을 위한 노력도 병행되어야 합니다. \\n\\n또한, AI가 인간의 인지 능력을 뛰어넘는 특이점(Singularity)에 도달할 것이라는 논의도 있지만, 이는 아직 먼 미래의 가설로 여겨집니다. 중요한 것은 현재 우리가 마주한 AI 기술의 실제적인 영향과 잠재적 위험을 이해하고, 이를 통제하고 관리할 수 있는 능력을 키우는 것입니다. AI는 단순한 도구가 아니라 사회 구조와 인간의 삶의 방식 자체를 변화시키는 강력한 힘을 가지고 있어, 군사 분야에서도 그 영향력이 크다고 할 수 있습니다.'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = db.as_retriever(search_kwargs = {\"k\" : 2})\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "''' 다음 컨텍스트만 사용하여 질문에 응답하시오.\n",
    "컨텍스트: {context}\n",
    "\n",
    "질문: {question}\n",
    "'''\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "  model = \"gpt-4o-mini\",\n",
    "  api_key=api_key,\n",
    "  temperature = 0.7,\n",
    ")\n",
    "\n",
    "@chain\n",
    "def qa(input):\n",
    "  # input에 대해 관련 문서 검색 \n",
    "  docs = retriever.invoke(input)\n",
    "  # 프롬프트 포멧 \n",
    "  formatted = prompt.invoke({'context': docs, \"question\" : input})\n",
    "  answer = llm.invoke(formatted)\n",
    "  return answer\n",
    "\n",
    "result = qa.invoke(query)\n",
    "result.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e345ad1e",
   "metadata": {},
   "source": [
    "## 4. Query Transformation\n",
    "기본 RAG 시스템은 사용자가 입력한 쿼리의 품질에 과도하게 영향을 받는데, 사용자마다 입력 품질이 다를 때 그 입력을 추상적이나 구체적으로 변환하는 전략이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09bba7d",
   "metadata": {},
   "source": [
    "### 4.1 Rewrite-Retrieve-Read(RRR) 전략 \n",
    "검색을 수행하기 전에 LLM에 사용자의 쿼리를 재작성하도록 프롬프트 전송하는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "38fb57b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AI(인공지능)는 21세기 가장 혁신적인 기술 중 하나로, 우리의 삶과 사회 전반에 걸쳐 막대한 영향을 미치고 있습니다. AI의 역사는 1950년대 다트머스 회의에서 \"인공지능\"이라는 용어가 처음 사용되면서 시작되었으며, 초기에는 주로 규칙 기반 시스템과 논리 추론에 중점을 두었습니다. 그러나 2000년대 이후 딥러닝 기술의 발전과 빅데이터의 등장이 AI 연구에 새로운 활력을 불어넣어, AI는 실생활에 적용되는 시대를 맞이하게 되었습니다. AI는 단순한 도구가 아니라, 사회 구조와 인간의 삶의 방식 자체를 변화시키는 강력한 힘을 가지고 있습니다.'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@chain\n",
    "def qa(input):\n",
    "  docs = retriever.invoke(input)\n",
    "  formatted_template = prompt.invoke({\"context\" : docs, \"question\" : input})\n",
    "  answer = llm.invoke(formatted_template)\n",
    "  \n",
    "  return answer\n",
    "\n",
    "# 불필요한 정보를 담은 query 전달 \n",
    "query = \"아침 6시에 일어나서 준비를 하고 외출을 했습니다. 아침은 먹지 않았어요. AI는 어떤 것인가요?\"\n",
    "\n",
    "result = qa.invoke(query)\n",
    "result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46327ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "재작성한 쿼리: AI의 정의와 역할은 무엇인가요\\\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'AI(인공지능)는 인간의 지능을 모방하여 다양한 작업을 수행할 수 있는 기술입니다. AI는 제너레이티브 AI와 멀티모달 AI와 같은 여러 형태로 발전하고 있으며, 텍스트, 이미지, 오디오 등 다양한 콘텐츠를 생성하고 이해하는 능력을 가지고 있습니다. AI는 또한 설명 가능한 AI(XAI)를 통해 의사결정 과정을 투명하게 이해할 수 있도록 도와주며, 윤리와 안전성에 대한 논의도 중요합니다. AI는 사회 구조와 인간의 삶의 방식을 변화시킬 수 있는 강력한 힘을 지니고 있습니다.'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### RRR 구현 \n",
    "\n",
    "rewrite_prompt = ChatPromptTemplate.from_template(\n",
    "'''\n",
    "웹 검색 엔진이 주어진 질문에 답할 수 있도록 더 나은 한글 검색어를 제공하세요. 쿼리는 \\'**'\\로 끝내세요\n",
    "\n",
    "질문: {x}\n",
    "\n",
    "답변: \n",
    "'''\n",
    ")\n",
    "\n",
    "def parse_rewriter_output(message):\n",
    "  return message.content.strip('\\'').strip('**')\n",
    "\n",
    "# 재작성 chain 정의 \n",
    "rewriter = rewrite_prompt | llm | parse_rewriter_output\n",
    "\n",
    "# RRR 로직 구현 \n",
    "@chain\n",
    "def qa_rrr(input):\n",
    "  new_query = rewriter.invoke(input)\n",
    "  print(f\"재작성한 쿼리: {new_query}\")\n",
    "  docs = retriever.invoke(new_query)\n",
    "  formatted = prompt.invoke({\"context\" : docs, \"question\" : input})\n",
    "  \n",
    "  answer = llm.invoke(formatted)\n",
    "  return answer \n",
    "\n",
    "result = qa_rrr.invoke(query)\n",
    "result.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197ab7c3",
   "metadata": {},
   "source": [
    "### 4.2 Multi Query Search\n",
    "초기 쿼리를 바탕으로 LLM에 여러 개의 쿼리를 생성하도록 지시한 후, 데이터 소스에서 각 쿼리에 대한 병렬 검색 수행 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "99dde81d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='\\n  당신은 AI 언어 모델 어시스턴트입니다. 주어진 사용자 질문의 다섯 가지 버전을 생성하여 벡터 데이터베이스 내에서 관련 문서를 검색하세요\\n  사용자 질문에 대한 다양한 관점을 생성함으로써 사용자가 거리 기반 유사도 검색의 한계를 극복할 수 있도록 돕는 것이 목표입니다. \\n  이러한 대체 질문을 개행으로 구분하여 제공하세요\\n  원래 질문: {question}\\n  '), additional_kwargs={})])\n",
       "| ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x0000027BB4DAE1D0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x0000027BBC785840>, root_client=<openai.OpenAI object at 0x0000027BB4DADF60>, root_async_client=<openai.AsyncOpenAI object at 0x0000027BB404C700>, model_name='gpt-4o-mini', temperature=0.7, model_kwargs={}, openai_api_key=SecretStr('**********'))\n",
       "| RunnableLambda(parse_queries_output)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perspectives_prompt = ChatPromptTemplate.from_template(\n",
    "  '''\n",
    "  당신은 AI 언어 모델 어시스턴트입니다. 주어진 사용자 질문의 다섯 가지 버전을 생성하여 벡터 데이터베이스 내에서 관련 문서를 검색하세요\n",
    "  사용자 질문에 대한 다양한 관점을 생성함으로써 사용자가 거리 기반 유사도 검색의 한계를 극복할 수 있도록 돕는 것이 목표입니다. \n",
    "  이러한 대체 질문을 개행으로 구분하여 제공하세요\n",
    "  원래 질문: {question}\n",
    "  '''\n",
    ")\n",
    "\n",
    "def parse_queries_output(message):\n",
    "  return message.content.split(\"\\n\")\n",
    "\n",
    "\n",
    "query_gen = perspectives_prompt | llm | parse_queries_output\n",
    "query_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "76224833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query_gen에서 생성된 쿼리 목록을 활용하여 관련성이 높은 문서를 뽑아낸 후 중복 제거 \n",
    "def get_unique_union(document_lists):\n",
    "  deduped_docs = {\n",
    "    # document_lists 내부의 sublist 내부의 doc를 추출하여 각 문서의 내용 추출\n",
    "    # 딕셔너리의 키는 유일성을 만족해야하므로 중복 제거 로직 \n",
    "    doc.page_content: doc for sublist in document_lists for doc in sublist\n",
    "  }\n",
    "  \n",
    "  return list(deduped_docs.values())\n",
    "\n",
    "# batch를 활용하여 생성된 모든 쿼리를 병렬로 실행 \n",
    "retrieval_chain = query_gen | retriever.batch | get_unique_union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4c63d36c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "다중 커리 검색\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'AI의 군사적 활용은 국제사회의 주요 관심사로 떠오르고 있습니다. 자율 살상 무기(LAWS)의 개발과 배치는 인류의 통제력을 벗어난 심각한 위협이 될 수 있다는 우려가 제기되고 있으며, 이에 대한 국제적인 합의와 규제 마련이 시급합니다. 이러한 논의와 함께 AI의 평화적 사용을 위한 노력도 병행되어야 합니다. AI가 인간의 인지 능력을 뛰어넘는 특이점(Singularity)에 도달할 것이라는 논의도 있지만, 이는 아직 먼 미래의 가설로 간주됩니다. 현재 중요한 것은 AI 기술의 실제적인 영향과 잠재적 위험을 이해하고, 이를 효과적으로 통제하고 관리할 수 있는 능력을 키우는 것입니다. AI는 단순한 도구가 아니라 사회 구조와 인간의 삶의 방식을 변화시키는 강력한 힘을 지니고 있습니다.'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\n",
    "''' 다음 컨텍스트만 사용하여 질문에 응답하시오.\n",
    "컨텍스트: {context}\n",
    "\n",
    "질문: {question}\n",
    "'''\n",
    ")\n",
    "\n",
    "query = \"군사 차원에서 인공지능에 대해 알려줘\"\n",
    "\n",
    "@chain\n",
    "def multi_query_qa(input):\n",
    "  docs = retrieval_chain.invoke(input)\n",
    "  formatted = prompt.invoke(\n",
    "    {\"context\" : docs, \"question\": input}\n",
    "  )\n",
    "  answer = llm.invoke(formatted)\n",
    "  return answer\n",
    "print(\"다중 커리 검색\\n\")\n",
    "result = multi_query_qa.invoke(query)\n",
    "\n",
    "result.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a293a7",
   "metadata": {},
   "source": [
    "### Query Routing \n",
    "벡터 저장소만 사용하는 편이 유용하더라도, 필요한 데이터는 RDB를 비롯한 다른 DB에 존재할 수 있는데, 이때 사용자의 질문을 바탕으로 쿼리를 라우팅하여 적절한 데이터 소스로 전달해 관련 문서를 검색하는 방법\n",
    "\n",
    "- **논리적 라우팅(logical routing)**: LLM에게 활용할 수 있는 여러 데이터 소스에 관한 정보를 제공해주어 쿼리를 토대로 적합한 데이터 소스를 선택하도록 하는 방식으로, 정의된 데이터 소스 목록이 존재하고 해당 소스로부터 관련 데이터를 검색하여 LLM에 적용해 정확한 결과물을 생성할 수 있을 때 논리적 라우팅 방식이 적합하다. \n",
    "\n",
    "- **의미론적 라우팅(semantic routing)**: 다양한 데이터 소스를 대표하는 프롬프트를 준비해 임베딩하고, 쿼리에 벡터 유사도 검색을 수행하여 가장 유사한 프롬프트를 검색하는 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368cf384",
   "metadata": {},
   "source": [
    "### 논리적 라우팅 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74ecf6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal # 둘 중 하나의 값만 가질 수 있는 타입 \n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from pydantic import BaseModel, Field \n",
    "\n",
    "# 데이터 모델 \n",
    "# json 형식으로 출력 \n",
    "class RouteQuery(BaseModel):\n",
    "  # Field는 데이터 모델에 추가적인 정보 제공 \n",
    "  datasource: Literal['python_docs','js_docs'] = Field(\n",
    "    ..., # 이 필드가 필수(required)임을 나타냄 \n",
    "    description = \"Given a user question, choose which dataource would be most relevant for answering their question\",\n",
    "  )\n",
    "  \n",
    "llm = ChatOpenAI(\n",
    "  model = \"gpt-4o-mini\",\n",
    "  api_key = api_key,\n",
    "  temperature=0.7\n",
    ")\n",
    "\n",
    "# 주어진 스키마와 일치하도록 형식화된 출력을 반환하는 모델 래퍼 \n",
    "structured_llm = llm.with_structured_output(RouteQuery)\n",
    "\n",
    "system = \"\"\"\n",
    "당신은 사용자 질문을 적절한 데이터 소스로 라우팅하는 전문가입니다. 질문이 지목하는 프로그래밍 언어에 따라 해당 데이터 소스로 라우팅 하세요\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "  [('system', system), ('human', '{question}')]\n",
    ")\n",
    "\n",
    "# 라우터 정의 \n",
    "router = prompt | structured_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "310eeedf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Routing to datasource='python_docs'\n"
     ]
    }
   ],
   "source": [
    "question = '''이 코드가 안 돌아가는 이유를 설명해줘\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "  'human', 'speak in {language}'\n",
    "])\n",
    "prompt.invoke('french')\n",
    "'''\n",
    "\n",
    "result = router.invoke({\"question\" : question})\n",
    "print(f\"\\nRouting to {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2fc13f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " choose route: chain for python_docs\n"
     ]
    }
   ],
   "source": [
    "## 추출된 값을 전달해서 라우팅 선택 함수 정의 \n",
    "\n",
    "def choose_route(result):\n",
    "  if 'python_docs' in result.datasource.lower():\n",
    "    return f'chain for python_docs'\n",
    "  else:\n",
    "    return 'chain for js_docs'\n",
    "\n",
    "# RunnableLambda을 통해 python 함수를 LCEL 체인에 통합하여 구성 \n",
    "full_chain = router | RunnableLambda(choose_route)\n",
    "\n",
    "result = full_chain.invoke({'question' : question})\n",
    "print(f\"\\n choose route: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f7138b",
   "metadata": {},
   "source": [
    "### 의미론적 라우팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9deb4e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "유사도: [0.75641031 0.82287172]\n",
      "스포츠 프롬프트 사용\n",
      "\n",
      " 의미론적 라우팅 결과 : 축구는 공을 발로 차서 상대팀 골대에 넣는 경기로, 11명으로 이루어진 두 팀이 경기를 진행하는 스포츠입니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain.utils.math import cosine_similarity\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import chain\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "\n",
    "# 다양한 데이터 소스를 대표하는 프롬프트를 미리 생성 \n",
    "\n",
    "physics_template = \"\"\" 당신은 매우 똑똑한 물리학 교수입니다.\n",
    "당신은 물리학에 대한 질문에 간결하고 쉽게 이해할 수 있는 방식으로 대답하는 데 뛰어납니다.\n",
    "당신이 질문에 대한 답을 모를 땐 모른다고 답변합니다.\n",
    "다음 질문에 대답하시오: {query}\n",
    "\"\"\"\n",
    "\n",
    "sports_template = \"\"\"당신은 매우 똑똑한 스포츠 지도자입니다.\n",
    "당신은 스포츠와 관련된 지식이나 규칙 등을 쉽게 이해할 수 있는 방식으로 대답하는 데 뛰어납니다. \n",
    "당신이 질문에 대한 답으 모를 땐 모른다고 답변합니다.\n",
    "다음 질문에 대답하시오: {query}\n",
    "\"\"\"\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "prompt_templates = [physics_template, sports_template]\n",
    "\n",
    "# 프롬프트 템플릿을 임베딩 \n",
    "prompt_embeddings = embeddings.embed_documents(prompt_templates)\n",
    "\n",
    "\n",
    "@chain\n",
    "\n",
    "def prompt_router(query):\n",
    "  # 입력 받은 query 임베딩 \n",
    "  # embedding 차원은 동일해야되며, query와 같이 단일 문자열을 받는 경우 embed_query메서드를 활용 \n",
    "  query_embeddings = embeddings.embed_query(query)\n",
    "  similarity = cosine_similarity([query_embeddings], prompt_embeddings)[0]\n",
    "  print(f\"유사도: {similarity}\")\n",
    "  most_similar_template = prompt_templates[similarity.argmax()] \n",
    "  \n",
    "  print(f\"스포츠 프롬프트 사용\" if most_similar_template == sports_template else \"물리 프롬프트 사용\")\n",
    "  \n",
    "  return PromptTemplate.from_template(most_similar_template)\n",
    "\n",
    "semantic_router = (prompt_router | ChatOpenAI() | StrOutputParser())\n",
    "\n",
    "result = semantic_router.invoke(\"축구는 무엇인가요?\")\n",
    "\n",
    "print(f\"\\n 의미론적 라우팅 결과 : {result}\")\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2db3b06",
   "metadata": {},
   "source": [
    "## Query construction\n",
    "\n",
    "자연어 쿼리를 사용 중인 데이터베이스나 데이터 소스의 쿼리 언어로 변환하는 과정 \n",
    "\n",
    "- 텍스트 to 메타데이터 필터: 대부분의 벡터 저장소는 메타데이터를 토대로 벡터 검색 범위를 제한하는 기능을 갖추고 있으므로 쿼리 호출에서 필터 표현식 지정이 가능하다.\n",
    "- 텍스트 to SQL\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37317e14",
   "metadata": {},
   "source": [
    "### Text-to-metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6e2f38f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lark\n",
      "  Downloading lark-1.2.2-py3-none-any.whl.metadata (1.8 kB)\n",
      "Downloading lark-1.2.2-py3-none-any.whl (111 kB)\n",
      "Installing collected packages: lark\n",
      "Successfully installed lark-1.2.2\n"
     ]
    }
   ],
   "source": [
    "!pip install lark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bed3ef60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChromaDB가 './chroma_db_data' 경로에서 성공적으로 로드되었습니다.\n",
      "로드된 문서의 개수: 10개\n",
      "[Document(metadata={'source': './data/test.txt'}, page_content='미래의 AI는 더욱 인간과 유사한 상호작용이 가능한 방향으로 발전할 것으로 예상됩니다. 제너레이티브 AI(생성형 AI)는 텍스트, 이미지, 오디오 등 다양한 형태의 콘텐츠를 스스로 생성하는 능력을 보여주며, 이는 창의적인 산업과 개인의 생산성을 혁신할 잠재력을 가지고 있습니다. 이와 함께 멀티모달 AI는 텍스트, 이미지, 음성 등 여러 형태의 데이터를 동시에 이해하고 처리하여 더욱 풍부한 상호작용을 가능하게 할 것입니다. 또한, 설명 가능한 AI(XAI)에 대한 연구가 활발히 진행되어 AI의 의사결정 과정을 투명하게 이해하고 신뢰성을 높이는 데 기여할 것입니다. AI 윤리와 안전성 또한 중요한 화두로 떠오르고 있으며, AI가 사회에 미치는 긍정적 영향을 극대화하고 부정적 영향을 최소화하기 위한 노력이 계속될 것입니다. 궁극적으로 AI는 인간의 지능을 보완하고 확장하여 인류의 삶의 질을 향상시키는 데 기여할 것입니다. 우리는 AI와 공존하며 새로운 시대를 열어갈 준비를 해야 합니다.'), Document(metadata={'source': './data/test.txt'}, page_content='인공지능(AI)은 21세기 가장 혁신적인 기술 중 하나로 손꼽히며, 우리의 삶과 사회 전반에 걸쳐 막대한 영향을 미치고 있습니다. AI의 역사는 1950년대 다트머스 회의에서 \"인공지능\"이라는 용어가 처음 사용되면서 시작되었습니다. 초기에는 주로 규칙 기반 시스템과 논리 추론에 중점을 두었으나, 계산 능력의 한계로 인해 \"AI 겨울\"이라는 침체기를 겪기도 했습니다. 그러나 2000년대 이후 딥러닝 기술의 발전과 빅데이터의 등장은 AI 연구에 새로운 활력을 불어넣었습니다. 특히 GPU와 같은 고성능 컴퓨팅 자원의 등장은 복잡한 신경망 모델을 훈련시키는 것을 가능하게 했습니다. 이러한 기술적 진보는 AI가 단순한 연구 단계를 넘어 실생활에 적용되는 시대를 열었습니다.'), Document(metadata={'source': './data/test.txt'}, page_content='AI의 군사적 활용 역시 국제사회의 주요 관심사입니다. 자율 살상 무기(LAWS)의 개발과 배치는 인류의 통제력을 벗어난 심각한 위협이 될 수 있다는 우려가 제기되고 있습니다. 이에 대한 국제적인 합의와 규제 마련이 시급하며, AI의 평화적 사용을 위한 노력이 병행되어야 합니다. AI가 인간의 인지 능력을 뛰어넘는 특이점(Singularity)에 도달할 것이라는 논의도 있지만, 이는 아직 먼 미래의 가설로 여겨집니다. 중요한 것은 현재 우리가 마주한 AI 기술의 실제적인 영향과 잠재적 위험을 이해하고, 이를 통제하고 관리할 수 있는 능력을 키우는 것입니다. AI는 단순히 도구가 아니라, 사회 구조와 인간의 삶의 방식 자체를 변화시키는 강력한 힘을 가지고 있기 때문입니다.'), Document(metadata={'source': './data/test.txt'}, page_content='결론적으로, AI는 인류에게 전례 없는 기회를 제공하는 동시에, 신중한 접근과 지속적인 논의를 요구하는 복잡한 기술입니다. 기술 발전의 속도에 발맞춰 사회적, 윤리적, 법적 프레임워크를 마련하고, 투명하고 책임감 있는 AI 개발과 활용을 위한 국제적인 협력이 필수적입니다. 우리는 AI의 잠재력을 최대한 활용하면서도, 그로 인한 위험을 최소화하고 모든 인류에게 혜택이 돌아갈 수 있도록 지혜를 모아야 할 것입니다. AI 교육의 확산과 대중의 이해 증진도 이러한 과정에서 중요한 역할을 합니다. 지속적인 연구와 사회적 합의를 통해 AI가 인류의 번영에 기여하는 길을 모색해야 합니다.')]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain.chains.query_constructor.schema import AttributeInfo # 데이터 소스 속성 정보 \n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "from langchain_community.vectorstores import Chroma \n",
    "\n",
    "\n",
    "fields = [\n",
    "  AttributeInfo(\n",
    "    name = 'genre',\n",
    "    description = '영화 장르',\n",
    "    type = 'string or list[string]',\n",
    "  ),\n",
    "  AttributeInfo(\n",
    "    name = 'year',\n",
    "    description = '영화 개봉 연도',\n",
    "    type = 'integer',\n",
    "  ),AttributeInfo(\n",
    "    name = 'director',\n",
    "    description = '영화 감독',\n",
    "    type = 'string',\n",
    "  ),AttributeInfo(\n",
    "    name = 'rating',\n",
    "    description = '영화 평점 1-10점',\n",
    "    type = 'float',\n",
    "  ),\n",
    "]\n",
    "\n",
    "persist_directory = \"./chroma_db_data\"\n",
    "\n",
    "vectorstore = Chroma(\n",
    "  persist_directory = persist_directory,\n",
    "  embedding_function = OpenAIEmbeddings()\n",
    ")\n",
    "# 디버깅 \n",
    "print(f\"ChromaDB가 '{persist_directory}' 경로에서 성공적으로 로드되었습니다.\")\n",
    "print(f\"로드된 문서의 개수: {vectorstore._collection.count()}개\")\n",
    "\n",
    "description = \"영화에 대한 간략한 정보\"\n",
    "\n",
    "llm = ChatOpenAI(model = \"gpt-4o-mini\", temperature = 0)\n",
    "\n",
    "# 벡터 스토오와 LLM을 사용하여 벡터 스토어 쿼리를 생성하는 검색기 \n",
    "retriever = SelfQueryRetriever.from_llm(llm, \n",
    "                                        vectorstore, \n",
    "                                        document_contents = description, \n",
    "                                        metadata_field_info = fields)\n",
    "\n",
    "# 필터 적용 \n",
    "print(retriever.invoke(\"미래 AI 관련된 내용만 보고싶어\"))\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8558c196",
   "metadata": {},
   "source": [
    "### Text-to-SQL\n",
    "\n",
    "LLM으로 사용자의 query를 SQL 쿼리로 변환할 수는 있지만, 오류가 발생할 여지가 존재하므로 다음과 같은 방법을 사용한다.\n",
    "\n",
    "- **데이터베이스 설명**: LLM에 정확한 데이터베이스 설명을 제공하여 SQL쿼리를 명확하게 만든다. 각 테이블에 대해 컬럼명과 자료형을 포함한 CREATE TABLE 을 LLM에 제공하고 테이블의 일부 예시 행을 제공한다. \n",
    "\n",
    "- **퓨샷 예시**: 프롬프트에 질문과 쿼리 간의 대응 예시 몇 가지를 첨부하여 쿼리 생성의 정확성을 높일 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca0c4e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'https://raw.githubusercontent.com/lerocha/chinook-database/master/ChinookDatabase/DataSources/Chinook_Sqlite.sql'에서 SQL 파일 다운로드 중...\n",
      "다운로드 완료.\n",
      "'data/Chinook.db' 데이터베이스 생성 및 SQL 실행 중...\n",
      "'data/Chinook.db' 데이터베이스가 성공적으로 생성되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import sqlite3\n",
    "import os\n",
    "\n",
    "# SQL 파일 다운로드 URL\n",
    "sql_url = \"https://raw.githubusercontent.com/lerocha/chinook-database/master/ChinookDatabase/DataSources/Chinook_Sqlite.sql\"\n",
    "\n",
    "output_path = \"data/\"\n",
    "db_filename = os.path.join(output_path, \"Chinook.db\")\n",
    "\n",
    "try:\n",
    "    if not os.path.exists(output_path):\n",
    "      os.makedirs(output_path)\n",
    "      print(f\"'{output_path}' 디렉터리를 생성했습니다.\")\n",
    "      \n",
    "    # SQL 내용 다운로드\n",
    "    print(f\"'{sql_url}'에서 SQL 파일 다운로드 중...\")\n",
    "    response = requests.get(sql_url)\n",
    "    response.raise_for_status() # HTTP 오류가 발생하면 예외를 발생시킵니다.\n",
    "    sql_content = response.text # response 객체 자체는 HTML body이므로 텍스트만 추출하여 저장 \n",
    "    print(\"다운로드 완료.\")\n",
    "\n",
    "    # SQLite 데이터베이스 연결 및 SQL 실행\n",
    "    print(f\"'{db_filename}' 데이터베이스 생성 및 SQL 실행 중...\")\n",
    "    conn = sqlite3.connect(db_filename) # DB 연결, 해당 filename의 DB가 존재하지 않는 경우 새로 생성 \n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # SQL 내용을 실행합니다.\n",
    "    # 여러 개의 SQL 문이 있을 수 있으므로 executescript를 사용합니다.\n",
    "    cursor.executescript(sql_content)\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "    print(f\"'{db_filename}' 데이터베이스가 성공적으로 생성되었습니다.\")\n",
    "\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"SQL 파일 다운로드 중 오류 발생: {e}\")\n",
    "except sqlite3.Error as e:\n",
    "    print(f\"SQLite 데이터베이스 작업 중 오류 발생: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"예상치 못한 오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3d20af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Album', 'Artist', 'Customer', 'Employee', 'Genre', 'Invoice', 'InvoiceLine', 'MediaType', 'Playlist', 'PlaylistTrack', 'Track']\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.tools import QuerySQLDataBaseTool\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "from langchain.chains import create_sql_query_chain\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# LLM에 Database의 스키마를 잘 이해할 수 있게 도움, 에이전트 또는 체인과 통합 가능 \n",
    "db = SQLDatabase.from_uri(\"sqlite:///data/Chinook.db\")\n",
    "print(db.get_usable_table_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd35a1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Error: (sqlite3.OperationalError) near \"SQLQuery\": syntax error\\n[SQL: SQLQuery: SELECT COUNT(*) AS \"EmployeeCount\" FROM \"Employee\";]\\n(Background on this error at: https://sqlalche.me/e/20/e3q8)'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = ChatOpenAI(model = 'gpt-4o-mini', temperature = 0.7)\n",
    "\n",
    "# 질문을 SQL 쿼리로 변환 \n",
    "write_query = create_sql_query_chain(llm, db)\n",
    "\n",
    "# SQL 쿼리 실행 \n",
    "execute_query = QuerySQLDataBaseTool(db = db)\n",
    "\n",
    "combined_chain = write_query | execute_query\n",
    "\n",
    "result = combined_chain.invoke({\"question\":\"직원(employee)은 모두 몇 명인가요?\"})\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df10a616",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[(8,)]'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableLambda \n",
    "\n",
    "# SQL 쿼리 정제 함수 정의 \n",
    "def clean_sql_output(sql_string):\n",
    "    if sql_string.strip().startswith(\"SQL\"):\n",
    "        # 접두사를 제외한 인덱스부터 문자열 추출 \n",
    "        # SQLQuery를 제외한 후 \":\"도 제거해야하므로 + 1\n",
    "        sql_string = sql_string.strip()[len('SQLQuery') + 1:].strip()\n",
    "        \n",
    "    sql_string = sql_string.strip()\n",
    "    return sql_string\n",
    "\n",
    "full_chain = write_query | RunnableLambda(clean_sql_output) | execute_query\n",
    "\n",
    "result = full_chain.invoke({\"question\": \"직원(employee)은 모두 몇 명인가요?\"})\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ragenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
