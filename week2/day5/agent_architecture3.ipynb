{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42eed975",
   "metadata": {},
   "source": [
    "### ì„œë¸Œê·¸ë˜í”„ë¥¼ í˜¸ì¶œí•˜ëŠ” í•¨ìˆ˜ \n",
    "\n",
    "í•¨ìˆ˜ëŠ” ë…¸ë“œì˜ ìƒíƒœ ì—…ë°ì´íŠ¸ë¥¼ ë°˜í™˜í•˜ê¸° ì „, ì„œë¸Œê·¸ë˜í”„ í˜¸ì¶œì„ ìœ„í•´ ì…ë ¥ ìƒíƒœë¥¼ ì„œë¸Œê·¸ë˜í”„ ìƒíƒœë¡œ ë³€í™˜í•˜ê³  ì„œë¸Œ ê·¸ë˜í”„ ê²°ê³¼ë¥¼ ë‹¤ì‹œ ìƒìœ„ ìƒíƒœë¡œ ë³µì›í•˜ëŠ” ê³¼ì •ì„ ìˆ˜í–‰í•´ì•¼ í•œë‹¤. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9dd027b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict\n",
    "from langgraph.graph import START, StateGraph\n",
    "\n",
    "class State(TypedDict):\n",
    "    foo: str # state key\n",
    "\n",
    "# ì„œë¸Œ ê·¸ë˜í”„ë¥¼ ì§ì ‘ í˜¸ì¶œí•˜ì§€ ì•Šìœ¼ë¯€ë¡œ state keyë¥¼ ê³µìœ í•˜ì§€ ì•ŠìŒ \n",
    "class SubgraphState(TypedDict):\n",
    "    bar: str \n",
    "    baz: str \n",
    "    \n",
    "# ì„œë¸Œ ê·¸ë˜í”„ ì •ì˜ \n",
    "def subgraph_node(state: SubgraphState):\n",
    "    return {\"bar\": state['bar'] + \"baz\"}\n",
    "\n",
    "subgraph_builder = StateGraph(SubgraphState)\n",
    "subgraph_builder.add_node(\"subgraph_node\", subgraph_node)\n",
    "subgraph_builder.add_edge(START, \"subgraph_node\")\n",
    "subgraph = subgraph_builder.compile() # ì„œë¸Œê·¸ë˜í”„ ì •ì˜ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cff1af8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì„œë¸Œê·¸ë˜í”„ë¥¼ í˜¸ì¶œí•˜ëŠ” ë¶€ëª¨ ê·¸ë˜í”„ ì •ì˜ \n",
    "\n",
    "def node(state: State):\n",
    "    # ë¶€ëª¨ ê·¸ë˜í”„ì˜ ìƒíƒœë¥¼ ì„œë¸Œ ê·¸ë˜í”„ ìƒíƒœë¡œ ë³€í™˜ \n",
    "    response = subgraph.invoke({'bar':state['foo']})\n",
    "    # ì‘ë‹µì„ ë‹¤ì‹œ ë¶€ëª¨ ê·¸ë˜í”„ì˜ ìƒíƒœë¡œ ë³€í™˜ \n",
    "    return {'foo': response['bar']}\n",
    "\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(\"node\", node)\n",
    "builder.add_edge(START, \"node\")\n",
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "061ff699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: {'foo': 'hellobaz'}\n"
     ]
    }
   ],
   "source": [
    "initial_state = {'foo':\"hello\"}\n",
    "result = graph.invoke(initial_state)\n",
    "\n",
    "print(\n",
    "    f\"Result: {result}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6458a1f5",
   "metadata": {},
   "source": [
    "### ë©€í‹° ì—ì´ì „íŠ¸ \n",
    "\n",
    "ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ì—¬ëŸ¬ ê°œì˜ ì†Œê·œëª¨ ë…ë¦½ ì—ì´ì „íŠ¸ë¡œ ë¶„í• í•œ í›„, ì´ë“¤ì„ ë©€í‹° ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œìœ¼ë¡œ êµ¬ì„±í•˜ëŠ” ë°©ì•ˆì„ ê°•êµ¬í•  ìˆ˜ ìˆë‹¤. ë…ë¦½ ì—ì´ì „íŠ¸ëŠ” í”„ë¡¬í”„íŠ¸ì™€ LLM í˜¸ì¶œë§Œìœ¼ë¡œ ê°„ë‹¨í•˜ê²Œ êµ¬ì„±í•  ìˆ˜ ìˆê³ , ReAct Agentì²˜ëŸ¼ ë³µì¡í•˜ê²Œ êµ¬í˜„í•˜ëŠ” ê²ƒë„ ê°€ëŠ¥í•˜ë‹¤. \n",
    "\n",
    "- ë…ë¦½ Agentê°€ ì—¬ëŸ¬ ê°œì˜ Toolì„ í™œìš©í•˜ëŠ” ë°©ì‹\n",
    "\n",
    "- Superviser ë°©ì‹: ëª¨ë“  ì—ì´ì „íŠ¸ê°€ ìŠˆí¼ë°”ì´ì € í•˜ë‚˜ì˜ ì—ì´ì „íŠ¸ì™€ í†µì‹ í•˜ë©°, ìŠˆí¼ë°”ì´ì € ì—ì´ì „íŠ¸ëŠ” ì´í›„ í˜¸ì¶œí•  ì—ì´ì „íŠ¸ë¥¼ ê²°ì •í•œë‹¤. \n",
    "\n",
    "- ë„¤íŠ¸ì›Œí¬ ë°©ì‹: ê° ì—ì´ì „íŠ¸ê°€ ë‹¤ë¥¸ ì—ì´ì „íŠ¸ì™€ ìƒí˜¸ í†µì‹ í•˜ì—¬ ëª¨ë“  ì—ì´ì „íŠ¸ê°€ ë‹¤ìŒì— ì‹¤í–‰ë  ì—ì´ì „íŠ¸ë¥¼ ê²°ì • ê°€ëŠ¥í•˜ë‹¤.\n",
    "\n",
    "- ê³„ì¸µí˜• ë°©ì‹: ì—¬ëŸ¬ ìŠˆí¼ë°”ì´ì €ë¥¼ ì´ê´„í•˜ëŠ” í•˜ë‚˜ì˜ ìŠˆí¼ë°”ì´ì €ë¥¼ í™œìš©í•˜ì—¬ ê´€ë¦¬í•˜ë„ë¡ ì„¤ê³„ëœ ë©€í‹° ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì„ ì •ì˜í•œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c3d638bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import StateGraph, MessagesState, START, END\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "from pydantic import BaseModel \n",
    "\n",
    "openai_api_key = load_dotenv(\"../../../.env\")\n",
    "\n",
    "class SupervisorDecision(BaseModel):\n",
    "    next: Literal['researcher','coder','FINISH']\n",
    "    \n",
    "# ëª¨ë¸ ì´ˆê¸°í™” \n",
    "model = ChatOpenAI(model = 'gpt-4o-mini', temperature=0)\n",
    "model = model.with_structured_output(SupervisorDecision) # ëª¨ë¸ì˜ ì¶œë ¥ í˜•ì‹ì„ ì •ì˜ \n",
    "\n",
    "# ì‚¬ìš© ê°€ëŠ¥í•œ ì—ì´ì „íŠ¸ ì •ì˜ \n",
    "agents = ['researcher', 'coder']\n",
    "\n",
    "system_prompt1 = f'''ë‹¹ì‹ ì€ ë‹¤ìŒ ì„œë¸Œì—ì´ì „íŠ¸ ì‚¬ì´ì˜ ëŒ€í™”ë¥¼ ê´€ë¦¬í•˜ëŠ” ìŠˆí¼ë°”ì´ì €ì…ë‹ˆë‹¤. \n",
    "ì„œë¸Œì—ì´ì „íŠ¸: {agents}. ì•„ë˜ ì‚¬ìš©ì ìš”ì²­ì— ë”°ë¼ ë‹¤ìŒìœ¼ë¡œ í–‰ë™í•  ì„œë¸Œì—ì´ì „íŠ¸ë¥¼ ì§€ëª©í•˜ì„¸ìš”,\n",
    "ê° ì„œë¸Œì—ì´ì „íŠ¸ëŠ” ì„ë¬´ë¥¼ ìˆ˜í–‰í•˜ê³  ê²°ê³¼ì™€ ìƒíƒœë¥¼ ì‘ë‹µí•©ë‹ˆë‹¤. ì‹¤í–‰í•  ì„œë¸Œ ì—ì´ì „íŠ¸ê°€ ì—†ê±°ë‚˜ ì‘ì—…ì´ ì™„ë£Œë˜ë©´ FINISHë¡œ ì‘ë‹µí•˜ì„¸ìš”'''\n",
    "\n",
    "system_prompt2 = f'''ìœ„ ëŒ€í™”ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ë‹¤ìŒìœ¼ë¡œ í–‰ë™í•  ì„œë¸Œì—ì´ì „íŠ¸ëŠ” ëˆ„êµ¬ì¸ê°€ìš”? \n",
    "ì•„ë‹ˆë©´ FINISH í•´ì•¼ í•©ë‹ˆê¹Œ? ì„œë¸Œì—ì´ì „íŠ¸:{', '.join(agents)}, FINISH'''\n",
    "\n",
    "def supervisor(state):\n",
    "    messages = [\n",
    "        SystemMessage(content=system_prompt1),\n",
    "        *state['messages'],\n",
    "        SystemMessage(content=system_prompt2)\n",
    "    ]\n",
    "\n",
    "    decision = model.invoke(messages)\n",
    "    print(f\"[Supervisor] Next agent: '{decision.next}'\")  # ë””ë²„ê¹… ë¡œê·¸\n",
    "\n",
    "    return {\"messages\": state['messages'] + [AIMessage(content=f\"Supervisor selected: {decision.next.strip()}\")]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecf3851",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(MessagesState):\n",
    "    next: Literal['researcher', 'coder', 'FINISH']\n",
    "\n",
    "# researcher ì—ì´ì „íŠ¸ ì •ì˜ \n",
    "def researcher(state):\n",
    "    last_user_message = state['messages'][-1].content # ê°€ì¥ ìµœê·¼ ë©”ì„¸ì§€ì˜ contentë§Œ ì €ì¥ \n",
    "    response = f\"Researcher is finding relevant information about: {last_user_message}\"\n",
    "    return {'messages': state['messages'] + [AIMessage(content=response)]}\n",
    "\n",
    "# coder ì—ì´ì „íŠ¸ ì •ì˜ \n",
    "def coder(state):\n",
    "    last_user_message = state['messages'][-1].content\n",
    "    response = f\"Coder is implementing code based on: {last_user_message}\"\n",
    "    return {'messages': state['messages'] + [AIMessage(content=response)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f1ff43",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# ë…¸ë“œ ì¶”ê°€\n",
    "workflow.add_node(\"supervisor\", supervisor)\n",
    "workflow.add_node(\"researcher\", researcher)\n",
    "workflow.add_node(\"coder\", coder)\n",
    "\n",
    "# supervisor ë…¸ë“œì—ì„œì˜ ë¶„ê¸° ì²˜ë¦¬\n",
    "# ì¡°ê±´ë¶€ ì—£ì§€ ì¶”ê°€ \n",
    "workflow.add_conditional_edges(\n",
    "    \"supervisor\",\n",
    "    lambda state: model.invoke([\n",
    "        ('system', system_prompt1),\n",
    "        *state['messages'],\n",
    "        ('system', system_prompt2)\n",
    "    ]).next,\n",
    "    {\n",
    "        \"researcher\": \"researcher\",\n",
    "        \"coder\": \"coder\",\n",
    "        \"FINISH\": END\n",
    "    }\n",
    ")\n",
    "\n",
    "# researcherì™€ coderëŠ” ë‹¤ì‹œ supervisorë¡œ\n",
    "workflow.add_edge(\"researcher\", \"supervisor\")\n",
    "workflow.add_edge(\"coder\", \"supervisor\")\n",
    "\n",
    "# ì‹œì‘ì  ì„¤ì •\n",
    "workflow.set_entry_point(\"supervisor\")\n",
    "\n",
    "# ê·¸ë˜í”„ ì»´íŒŒì¼\n",
    "graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "57ba3669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Supervisor] Next agent: 'coder'\n",
      "[Supervisor] Next agent: 'FINISH'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Create a Python web scraper that collects book titles from an online bookstore.', additional_kwargs={}, response_metadata={}, id='d148c1ae-6a7b-42f2-9d65-1ee29357a7ae'),\n",
       "  AIMessage(content='Supervisor selected: coder', additional_kwargs={}, response_metadata={}, id='99550565-5942-403d-bc12-631437f0a85e'),\n",
       "  AIMessage(content='ğŸ’» Coder is implementing code based on: Supervisor selected: coder', additional_kwargs={}, response_metadata={}, id='ac752b8f-a2a3-4ff2-8b03-8e4fa9837cf4'),\n",
       "  AIMessage(content='Supervisor selected: FINISH', additional_kwargs={}, response_metadata={}, id='c41d7926-f7f5-4560-a9cd-11b1f8994265')]}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ì´ˆê¸° ë©”ì‹œì§€ ìƒíƒœ ì •ì˜\n",
    "inputs = {\n",
    "    'messages': [('human', 'Create a Python web scraper that collects book titles from an online bookstore.')]\n",
    "}\n",
    "\n",
    "# ì‹¤í–‰\n",
    "result = graph.invoke(inputs)\n",
    "\n",
    "# ì¶œë ¥ í™•ì¸\n",
    "result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b94f48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ragenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
