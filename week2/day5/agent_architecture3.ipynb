{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42eed975",
   "metadata": {},
   "source": [
    "### 서브그래프를 호출하는 함수 \n",
    "\n",
    "함수는 노드의 상태 업데이트를 반환하기 전, 서브그래프 호출을 위해 입력 상태를 서브그래프 상태로 변환하고 서브 그래프 결과를 다시 상위 상태로 복원하는 과정을 수행해야 한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9dd027b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict\n",
    "from langgraph.graph import START, StateGraph\n",
    "\n",
    "class State(TypedDict):\n",
    "    foo: str # state key\n",
    "\n",
    "# 서브 그래프를 직접 호출하지 않으므로 state key를 공유하지 않음 \n",
    "class SubgraphState(TypedDict):\n",
    "    bar: str \n",
    "    baz: str \n",
    "    \n",
    "# 서브 그래프 정의 \n",
    "def subgraph_node(state: SubgraphState):\n",
    "    return {\"bar\": state['bar'] + \"baz\"}\n",
    "\n",
    "subgraph_builder = StateGraph(SubgraphState)\n",
    "subgraph_builder.add_node(\"subgraph_node\", subgraph_node)\n",
    "subgraph_builder.add_edge(START, \"subgraph_node\")\n",
    "subgraph = subgraph_builder.compile() # 서브그래프 정의 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cff1af8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 서브그래프를 호출하는 부모 그래프 정의 \n",
    "\n",
    "def node(state: State):\n",
    "    # 부모 그래프의 상태를 서브 그래프 상태로 변환 \n",
    "    response = subgraph.invoke({'bar':state['foo']})\n",
    "    # 응답을 다시 부모 그래프의 상태로 변환 \n",
    "    return {'foo': response['bar']}\n",
    "\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(\"node\", node)\n",
    "builder.add_edge(START, \"node\")\n",
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "061ff699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: {'foo': 'hellobaz'}\n"
     ]
    }
   ],
   "source": [
    "initial_state = {'foo':\"hello\"}\n",
    "result = graph.invoke(initial_state)\n",
    "\n",
    "print(\n",
    "    f\"Result: {result}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6458a1f5",
   "metadata": {},
   "source": [
    "### 멀티 에이전트 \n",
    "\n",
    "애플리케이션을 여러 개의 소규모 독립 에이전트로 분할한 후, 이들을 멀티 에이전트 시스템으로 구성하는 방안을 강구할 수 있다. 독립 에이전트는 프롬프트와 LLM 호출만으로 간단하게 구성할 수 있고, ReAct Agent처럼 복잡하게 구현하는 것도 가능하다. \n",
    "\n",
    "- 독립 Agent가 여러 개의 Tool을 활용하는 방식\n",
    "\n",
    "- Superviser 방식: 모든 에이전트가 슈퍼바이저 하나의 에이전트와 통신하며, 슈퍼바이저 에이전트는 이후 호출할 에이전트를 결정한다. \n",
    "\n",
    "- 네트워크 방식: 각 에이전트가 다른 에이전트와 상호 통신하여 모든 에이전트가 다음에 실행될 에이전트를 결정 가능하다.\n",
    "\n",
    "- 계층형 방식: 여러 슈퍼바이저를 총괄하는 하나의 슈퍼바이저를 활용하여 관리하도록 설계된 멀티 에이전트 시스템을 정의한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c3d638bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import StateGraph, MessagesState, START, END\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "from pydantic import BaseModel \n",
    "\n",
    "openai_api_key = load_dotenv(\"../../../.env\")\n",
    "\n",
    "class SupervisorDecision(BaseModel):\n",
    "    next: Literal['researcher','coder','FINISH']\n",
    "    \n",
    "# 모델 초기화 \n",
    "model = ChatOpenAI(model = 'gpt-4o-mini', temperature=0)\n",
    "model = model.with_structured_output(SupervisorDecision) # 모델의 출력 형식을 정의 \n",
    "\n",
    "# 사용 가능한 에이전트 정의 \n",
    "agents = ['researcher', 'coder']\n",
    "\n",
    "system_prompt1 = f'''당신은 다음 서브에이전트 사이의 대화를 관리하는 슈퍼바이저입니다. \n",
    "서브에이전트: {agents}. 아래 사용자 요청에 따라 다음으로 행동할 서브에이전트를 지목하세요,\n",
    "각 서브에이전트는 임무를 수행하고 결과와 상태를 응답합니다. 실행할 서브 에이전트가 없거나 작업이 완료되면 FINISH로 응답하세요'''\n",
    "\n",
    "system_prompt2 = f'''위 대화를 바탕으로, 다음으로 행동할 서브에이전트는 누구인가요? \n",
    "아니면 FINISH 해야 합니까? 서브에이전트:{', '.join(agents)}, FINISH'''\n",
    "\n",
    "def supervisor(state):\n",
    "    messages = [\n",
    "        SystemMessage(content=system_prompt1),\n",
    "        *state['messages'],\n",
    "        SystemMessage(content=system_prompt2)\n",
    "    ]\n",
    "\n",
    "    decision = model.invoke(messages)\n",
    "    print(f\"[Supervisor] Next agent: '{decision.next}'\")  # 디버깅 로그\n",
    "\n",
    "    return {\"messages\": state['messages'] + [AIMessage(content=f\"Supervisor selected: {decision.next.strip()}\")]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecf3851",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(MessagesState):\n",
    "    next: Literal['researcher', 'coder', 'FINISH']\n",
    "\n",
    "# researcher 에이전트 정의 \n",
    "def researcher(state):\n",
    "    last_user_message = state['messages'][-1].content # 가장 최근 메세지의 content만 저장 \n",
    "    response = f\"Researcher is finding relevant information about: {last_user_message}\"\n",
    "    return {'messages': state['messages'] + [AIMessage(content=response)]}\n",
    "\n",
    "# coder 에이전트 정의 \n",
    "def coder(state):\n",
    "    last_user_message = state['messages'][-1].content\n",
    "    response = f\"Coder is implementing code based on: {last_user_message}\"\n",
    "    return {'messages': state['messages'] + [AIMessage(content=response)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f1ff43",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# 노드 추가\n",
    "workflow.add_node(\"supervisor\", supervisor)\n",
    "workflow.add_node(\"researcher\", researcher)\n",
    "workflow.add_node(\"coder\", coder)\n",
    "\n",
    "# supervisor 노드에서의 분기 처리\n",
    "# 조건부 엣지 추가 \n",
    "workflow.add_conditional_edges(\n",
    "    \"supervisor\",\n",
    "    lambda state: model.invoke([\n",
    "        ('system', system_prompt1),\n",
    "        *state['messages'],\n",
    "        ('system', system_prompt2)\n",
    "    ]).next,\n",
    "    {\n",
    "        \"researcher\": \"researcher\",\n",
    "        \"coder\": \"coder\",\n",
    "        \"FINISH\": END\n",
    "    }\n",
    ")\n",
    "\n",
    "# researcher와 coder는 다시 supervisor로\n",
    "workflow.add_edge(\"researcher\", \"supervisor\")\n",
    "workflow.add_edge(\"coder\", \"supervisor\")\n",
    "\n",
    "# 시작점 설정\n",
    "workflow.set_entry_point(\"supervisor\")\n",
    "\n",
    "# 그래프 컴파일\n",
    "graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "57ba3669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Supervisor] Next agent: 'coder'\n",
      "[Supervisor] Next agent: 'FINISH'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Create a Python web scraper that collects book titles from an online bookstore.', additional_kwargs={}, response_metadata={}, id='d148c1ae-6a7b-42f2-9d65-1ee29357a7ae'),\n",
       "  AIMessage(content='Supervisor selected: coder', additional_kwargs={}, response_metadata={}, id='99550565-5942-403d-bc12-631437f0a85e'),\n",
       "  AIMessage(content='💻 Coder is implementing code based on: Supervisor selected: coder', additional_kwargs={}, response_metadata={}, id='ac752b8f-a2a3-4ff2-8b03-8e4fa9837cf4'),\n",
       "  AIMessage(content='Supervisor selected: FINISH', additional_kwargs={}, response_metadata={}, id='c41d7926-f7f5-4560-a9cd-11b1f8994265')]}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 초기 메시지 상태 정의\n",
    "inputs = {\n",
    "    'messages': [('human', 'Create a Python web scraper that collects book titles from an online bookstore.')]\n",
    "}\n",
    "\n",
    "# 실행\n",
    "result = graph.invoke(inputs)\n",
    "\n",
    "# 출력 확인\n",
    "result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b94f48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ragenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
